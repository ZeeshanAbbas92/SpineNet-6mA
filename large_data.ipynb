{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61600, 41, 4) (184800, 41, 4)\n",
      "(184800, 41, 4) (61600, 41, 4) (61600, 41, 4)\n",
      "Train on 184800 samples, validate on 61600 samples\n",
      "Epoch 1/100\n",
      "184800/184800 [==============================] - 94s 507us/step - loss: 0.2451 - binary_accuracy: 0.9052 - val_loss: 0.2124 - val_binary_accuracy: 0.9191\n",
      "Epoch 2/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1995 - binary_accuracy: 0.9273 - val_loss: 0.1967 - val_binary_accuracy: 0.9227\n",
      "Epoch 3/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1891 - binary_accuracy: 0.9307 - val_loss: 0.1839 - val_binary_accuracy: 0.9280\n",
      "Epoch 4/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1823 - binary_accuracy: 0.9335 - val_loss: 0.1792 - val_binary_accuracy: 0.9284\n",
      "Epoch 5/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.1764 - binary_accuracy: 0.9356 - val_loss: 0.1793 - val_binary_accuracy: 0.9290\n",
      "Epoch 6/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1723 - binary_accuracy: 0.9368 - val_loss: 0.1747 - val_binary_accuracy: 0.9310\n",
      "Epoch 7/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1685 - binary_accuracy: 0.9381 - val_loss: 0.1736 - val_binary_accuracy: 0.9317\n",
      "Epoch 8/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.1652 - binary_accuracy: 0.9395 - val_loss: 0.1705 - val_binary_accuracy: 0.9325\n",
      "Epoch 9/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1602 - binary_accuracy: 0.9411 - val_loss: 0.1718 - val_binary_accuracy: 0.9320\n",
      "Epoch 10/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1578 - binary_accuracy: 0.9424 - val_loss: 0.1744 - val_binary_accuracy: 0.9332\n",
      "Epoch 11/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1533 - binary_accuracy: 0.9441 - val_loss: 0.1719 - val_binary_accuracy: 0.9325\n",
      "Epoch 12/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1485 - binary_accuracy: 0.9452 - val_loss: 0.1670 - val_binary_accuracy: 0.9327\n",
      "Epoch 13/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1448 - binary_accuracy: 0.9470 - val_loss: 0.1592 - val_binary_accuracy: 0.9375\n",
      "Epoch 14/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.1412 - binary_accuracy: 0.9483 - val_loss: 0.1643 - val_binary_accuracy: 0.9372\n",
      "Epoch 15/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1378 - binary_accuracy: 0.9495 - val_loss: 0.1584 - val_binary_accuracy: 0.9380\n",
      "Epoch 16/100\n",
      "184800/184800 [==============================] - 88s 476us/step - loss: 0.1351 - binary_accuracy: 0.9506 - val_loss: 0.1590 - val_binary_accuracy: 0.9373\n",
      "Epoch 17/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1319 - binary_accuracy: 0.9520 - val_loss: 0.1641 - val_binary_accuracy: 0.9372\n",
      "Epoch 18/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.1288 - binary_accuracy: 0.9528 - val_loss: 0.1582 - val_binary_accuracy: 0.9394\n",
      "Epoch 19/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1273 - binary_accuracy: 0.9539 - val_loss: 0.1640 - val_binary_accuracy: 0.9371\n",
      "Epoch 20/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1237 - binary_accuracy: 0.9550 - val_loss: 0.1566 - val_binary_accuracy: 0.9409\n",
      "Epoch 21/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.1215 - binary_accuracy: 0.9557 - val_loss: 0.1575 - val_binary_accuracy: 0.9404\n",
      "Epoch 22/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1193 - binary_accuracy: 0.9565 - val_loss: 0.1559 - val_binary_accuracy: 0.9418\n",
      "Epoch 23/100\n",
      "184800/184800 [==============================] - 88s 479us/step - loss: 0.1174 - binary_accuracy: 0.9574 - val_loss: 0.1556 - val_binary_accuracy: 0.9419\n",
      "Epoch 24/100\n",
      "184800/184800 [==============================] - 88s 476us/step - loss: 0.1161 - binary_accuracy: 0.9578 - val_loss: 0.1541 - val_binary_accuracy: 0.9433\n",
      "Epoch 25/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.1147 - binary_accuracy: 0.9585 - val_loss: 0.1581 - val_binary_accuracy: 0.9416\n",
      "Epoch 26/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1124 - binary_accuracy: 0.9592 - val_loss: 0.1532 - val_binary_accuracy: 0.9433\n",
      "Epoch 27/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.1105 - binary_accuracy: 0.9600 - val_loss: 0.1523 - val_binary_accuracy: 0.9445\n",
      "Epoch 28/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1098 - binary_accuracy: 0.9604 - val_loss: 0.1552 - val_binary_accuracy: 0.9440\n",
      "Epoch 29/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1080 - binary_accuracy: 0.9609 - val_loss: 0.1520 - val_binary_accuracy: 0.9443\n",
      "Epoch 30/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1077 - binary_accuracy: 0.9610 - val_loss: 0.1547 - val_binary_accuracy: 0.9441\n",
      "Epoch 31/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.1065 - binary_accuracy: 0.9613 - val_loss: 0.1547 - val_binary_accuracy: 0.9445\n",
      "Epoch 32/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.1055 - binary_accuracy: 0.9621 - val_loss: 0.1523 - val_binary_accuracy: 0.9456\n",
      "Epoch 33/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1048 - binary_accuracy: 0.9622 - val_loss: 0.1569 - val_binary_accuracy: 0.9437\n",
      "Epoch 34/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1034 - binary_accuracy: 0.9625 - val_loss: 0.1547 - val_binary_accuracy: 0.9447\n",
      "Epoch 35/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1027 - binary_accuracy: 0.9626 - val_loss: 0.1519 - val_binary_accuracy: 0.9454\n",
      "Epoch 36/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1031 - binary_accuracy: 0.9627 - val_loss: 0.1561 - val_binary_accuracy: 0.9445\n",
      "Epoch 37/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1009 - binary_accuracy: 0.9638 - val_loss: 0.1538 - val_binary_accuracy: 0.9458\n",
      "Epoch 38/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.1004 - binary_accuracy: 0.9639 - val_loss: 0.1537 - val_binary_accuracy: 0.9463\n",
      "Epoch 39/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.1002 - binary_accuracy: 0.9640 - val_loss: 0.1551 - val_binary_accuracy: 0.9453\n",
      "Epoch 40/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0999 - binary_accuracy: 0.9638 - val_loss: 0.1546 - val_binary_accuracy: 0.9456\n",
      "Epoch 41/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0988 - binary_accuracy: 0.9642 - val_loss: 0.1541 - val_binary_accuracy: 0.9460\n",
      "Epoch 42/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0992 - binary_accuracy: 0.9642 - val_loss: 0.1537 - val_binary_accuracy: 0.9464\n",
      "Epoch 43/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0983 - binary_accuracy: 0.9648 - val_loss: 0.1532 - val_binary_accuracy: 0.9461\n",
      "Epoch 44/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0983 - binary_accuracy: 0.9648 - val_loss: 0.1534 - val_binary_accuracy: 0.9462\n",
      "Epoch 45/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0975 - binary_accuracy: 0.9649 - val_loss: 0.1526 - val_binary_accuracy: 0.9466\n",
      "Epoch 46/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.0977 - binary_accuracy: 0.9645 - val_loss: 0.1541 - val_binary_accuracy: 0.9462\n",
      "Epoch 47/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0976 - binary_accuracy: 0.9647 - val_loss: 0.1534 - val_binary_accuracy: 0.9465\n",
      "Epoch 48/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0972 - binary_accuracy: 0.9649 - val_loss: 0.1549 - val_binary_accuracy: 0.9464\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0982 - binary_accuracy: 0.9648 - val_loss: 0.1542 - val_binary_accuracy: 0.9466\n",
      "Epoch 50/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.0979 - binary_accuracy: 0.9646 - val_loss: 0.1537 - val_binary_accuracy: 0.9466\n",
      "Epoch 51/100\n",
      "184800/184800 [==============================] - 91s 491us/step - loss: 0.0977 - binary_accuracy: 0.9647 - val_loss: 0.1539 - val_binary_accuracy: 0.9462\n",
      "Epoch 52/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0960 - binary_accuracy: 0.9655 - val_loss: 0.1539 - val_binary_accuracy: 0.9466\n",
      "Epoch 53/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0957 - binary_accuracy: 0.9658 - val_loss: 0.1528 - val_binary_accuracy: 0.9471\n",
      "Epoch 54/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0951 - binary_accuracy: 0.9657 - val_loss: 0.1551 - val_binary_accuracy: 0.9462\n",
      "Epoch 55/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0965 - binary_accuracy: 0.9648 - val_loss: 0.1541 - val_binary_accuracy: 0.9463\n",
      "Epoch 56/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0963 - binary_accuracy: 0.9656 - val_loss: 0.1533 - val_binary_accuracy: 0.9467\n",
      "Epoch 57/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0952 - binary_accuracy: 0.9659 - val_loss: 0.1535 - val_binary_accuracy: 0.9468\n",
      "Epoch 58/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.0961 - binary_accuracy: 0.9654 - val_loss: 0.1545 - val_binary_accuracy: 0.9465\n",
      "Epoch 59/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0955 - binary_accuracy: 0.9655 - val_loss: 0.1533 - val_binary_accuracy: 0.9471\n",
      "Epoch 60/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0961 - binary_accuracy: 0.9651 - val_loss: 0.1537 - val_binary_accuracy: 0.9469\n",
      "Epoch 61/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0959 - binary_accuracy: 0.9654 - val_loss: 0.1534 - val_binary_accuracy: 0.9468\n",
      "Epoch 62/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0950 - binary_accuracy: 0.9658 - val_loss: 0.1539 - val_binary_accuracy: 0.9470\n",
      "Epoch 63/100\n",
      "184800/184800 [==============================] - 90s 484us/step - loss: 0.0956 - binary_accuracy: 0.9654 - val_loss: 0.1534 - val_binary_accuracy: 0.9469\n",
      "Epoch 64/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0957 - binary_accuracy: 0.9660 - val_loss: 0.1534 - val_binary_accuracy: 0.9468\n",
      "Epoch 65/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0950 - binary_accuracy: 0.9656 - val_loss: 0.1540 - val_binary_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.0959 - binary_accuracy: 0.9654 - val_loss: 0.1533 - val_binary_accuracy: 0.9469\n",
      "Epoch 67/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0945 - binary_accuracy: 0.9660 - val_loss: 0.1541 - val_binary_accuracy: 0.9470\n",
      "Epoch 68/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0959 - binary_accuracy: 0.9656 - val_loss: 0.1538 - val_binary_accuracy: 0.9472\n",
      "Epoch 69/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0956 - binary_accuracy: 0.9657 - val_loss: 0.1534 - val_binary_accuracy: 0.9470\n",
      "Epoch 70/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0958 - binary_accuracy: 0.9660 - val_loss: 0.1533 - val_binary_accuracy: 0.9472\n",
      "Epoch 71/100\n",
      "184800/184800 [==============================] - 91s 490us/step - loss: 0.0947 - binary_accuracy: 0.9663 - val_loss: 0.1539 - val_binary_accuracy: 0.9468\n",
      "Epoch 72/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0951 - binary_accuracy: 0.9660 - val_loss: 0.1539 - val_binary_accuracy: 0.9469\n",
      "Epoch 73/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0945 - binary_accuracy: 0.9660 - val_loss: 0.1538 - val_binary_accuracy: 0.9468\n",
      "Epoch 74/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0956 - binary_accuracy: 0.9659 - val_loss: 0.1538 - val_binary_accuracy: 0.9471\n",
      "Epoch 75/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0956 - binary_accuracy: 0.9657 - val_loss: 0.1542 - val_binary_accuracy: 0.9470\n",
      "Epoch 76/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0955 - binary_accuracy: 0.9657 - val_loss: 0.1537 - val_binary_accuracy: 0.9471\n",
      "Epoch 77/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0951 - binary_accuracy: 0.9651 - val_loss: 0.1540 - val_binary_accuracy: 0.9469\n",
      "Epoch 78/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0946 - binary_accuracy: 0.9659 - val_loss: 0.1538 - val_binary_accuracy: 0.9468\n",
      "Epoch 79/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0955 - binary_accuracy: 0.9655 - val_loss: 0.1539 - val_binary_accuracy: 0.9469\n",
      "Epoch 80/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0948 - binary_accuracy: 0.9660 - val_loss: 0.1539 - val_binary_accuracy: 0.9470\n",
      "Epoch 81/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0958 - binary_accuracy: 0.9654 - val_loss: 0.1539 - val_binary_accuracy: 0.9470\n",
      "Epoch 82/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0948 - binary_accuracy: 0.9662 - val_loss: 0.1536 - val_binary_accuracy: 0.9471\n",
      "Epoch 83/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0955 - binary_accuracy: 0.9659 - val_loss: 0.1539 - val_binary_accuracy: 0.9470\n",
      "Epoch 84/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0960 - binary_accuracy: 0.9654 - val_loss: 0.1538 - val_binary_accuracy: 0.9470\n",
      "Epoch 85/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0948 - binary_accuracy: 0.9659 - val_loss: 0.1537 - val_binary_accuracy: 0.9469\n",
      "Epoch 86/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0961 - binary_accuracy: 0.9654 - val_loss: 0.1537 - val_binary_accuracy: 0.9471\n",
      "Epoch 87/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0954 - binary_accuracy: 0.9657 - val_loss: 0.1538 - val_binary_accuracy: 0.9469\n",
      "Epoch 88/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0948 - binary_accuracy: 0.9658 - val_loss: 0.1537 - val_binary_accuracy: 0.9468\n",
      "Epoch 89/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0953 - binary_accuracy: 0.9657 - val_loss: 0.1537 - val_binary_accuracy: 0.9471\n",
      "Epoch 90/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0945 - binary_accuracy: 0.9661 - val_loss: 0.1536 - val_binary_accuracy: 0.9469\n",
      "Epoch 91/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0952 - binary_accuracy: 0.9653 - val_loss: 0.1536 - val_binary_accuracy: 0.9470\n",
      "Epoch 92/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0951 - binary_accuracy: 0.9658 - val_loss: 0.1537 - val_binary_accuracy: 0.9471\n",
      "Epoch 93/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0944 - binary_accuracy: 0.9662 - val_loss: 0.1535 - val_binary_accuracy: 0.9468\n",
      "Epoch 94/100\n",
      "184800/184800 [==============================] - 90s 484us/step - loss: 0.0949 - binary_accuracy: 0.9659 - val_loss: 0.1535 - val_binary_accuracy: 0.9467\n",
      "Epoch 95/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0948 - binary_accuracy: 0.9657 - val_loss: 0.1537 - val_binary_accuracy: 0.9469\n",
      "Epoch 96/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0950 - binary_accuracy: 0.9653 - val_loss: 0.1537 - val_binary_accuracy: 0.9470\n",
      "Epoch 97/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0944 - binary_accuracy: 0.9660 - val_loss: 0.1538 - val_binary_accuracy: 0.9468\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0944 - binary_accuracy: 0.9658 - val_loss: 0.1538 - val_binary_accuracy: 0.9469\n",
      "Epoch 99/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0946 - binary_accuracy: 0.9656 - val_loss: 0.1538 - val_binary_accuracy: 0.9470\n",
      "Epoch 100/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0960 - binary_accuracy: 0.9656 - val_loss: 0.1538 - val_binary_accuracy: 0.9469\n",
      "184800/184800 [==============================] - 31s 166us/step\n",
      "(184800,)\n",
      "(184800,)\n",
      "61600/61600 [==============================] - 10s 168us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "61600/61600 [==============================] - 10s 167us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "(61600, 41, 4) (184800, 41, 4)\n",
      "(184800, 41, 4) (61600, 41, 4) (61600, 41, 4)\n",
      "Train on 184800 samples, validate on 61600 samples\n",
      "Epoch 1/100\n",
      "184800/184800 [==============================] - 91s 492us/step - loss: 0.2326 - binary_accuracy: 0.9113 - val_loss: 0.2070 - val_binary_accuracy: 0.9227\n",
      "Epoch 2/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.1948 - binary_accuracy: 0.9278 - val_loss: 0.1959 - val_binary_accuracy: 0.9263\n",
      "Epoch 3/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1851 - binary_accuracy: 0.9309 - val_loss: 0.1916 - val_binary_accuracy: 0.9273\n",
      "Epoch 4/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.1783 - binary_accuracy: 0.9336 - val_loss: 0.1904 - val_binary_accuracy: 0.9286\n",
      "Epoch 5/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1716 - binary_accuracy: 0.9361 - val_loss: 0.1856 - val_binary_accuracy: 0.9303\n",
      "Epoch 6/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1673 - binary_accuracy: 0.9379 - val_loss: 0.1918 - val_binary_accuracy: 0.9291\n",
      "Epoch 7/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1621 - binary_accuracy: 0.9397 - val_loss: 0.1804 - val_binary_accuracy: 0.9318\n",
      "Epoch 8/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1585 - binary_accuracy: 0.9412 - val_loss: 0.1778 - val_binary_accuracy: 0.9334\n",
      "Epoch 9/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1543 - binary_accuracy: 0.9424 - val_loss: 0.1783 - val_binary_accuracy: 0.9350\n",
      "Epoch 10/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.1514 - binary_accuracy: 0.9436 - val_loss: 0.1724 - val_binary_accuracy: 0.9358\n",
      "Epoch 11/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1461 - binary_accuracy: 0.9457 - val_loss: 0.1771 - val_binary_accuracy: 0.9354\n",
      "Epoch 12/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.1413 - binary_accuracy: 0.9478 - val_loss: 0.1706 - val_binary_accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1375 - binary_accuracy: 0.9497 - val_loss: 0.1776 - val_binary_accuracy: 0.9364\n",
      "Epoch 14/100\n",
      "184800/184800 [==============================] - 90s 484us/step - loss: 0.1341 - binary_accuracy: 0.9505 - val_loss: 0.1744 - val_binary_accuracy: 0.9375\n",
      "Epoch 15/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.1296 - binary_accuracy: 0.9521 - val_loss: 0.1712 - val_binary_accuracy: 0.9387\n",
      "Epoch 16/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.1264 - binary_accuracy: 0.9533 - val_loss: 0.1675 - val_binary_accuracy: 0.9405\n",
      "Epoch 17/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.1233 - binary_accuracy: 0.9548 - val_loss: 0.1662 - val_binary_accuracy: 0.9414\n",
      "Epoch 18/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1200 - binary_accuracy: 0.9565 - val_loss: 0.1660 - val_binary_accuracy: 0.9418\n",
      "Epoch 19/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.1174 - binary_accuracy: 0.9569 - val_loss: 0.1650 - val_binary_accuracy: 0.9428\n",
      "Epoch 20/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.1143 - binary_accuracy: 0.9583 - val_loss: 0.1664 - val_binary_accuracy: 0.9429\n",
      "Epoch 21/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.1128 - binary_accuracy: 0.9593 - val_loss: 0.1665 - val_binary_accuracy: 0.9431\n",
      "Epoch 22/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.1099 - binary_accuracy: 0.9602 - val_loss: 0.1667 - val_binary_accuracy: 0.9438\n",
      "Epoch 23/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.1080 - binary_accuracy: 0.9607 - val_loss: 0.1619 - val_binary_accuracy: 0.9448\n",
      "Epoch 24/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.1065 - binary_accuracy: 0.9611 - val_loss: 0.1649 - val_binary_accuracy: 0.9446\n",
      "Epoch 25/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1043 - binary_accuracy: 0.9619 - val_loss: 0.1651 - val_binary_accuracy: 0.9447\n",
      "Epoch 26/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.1024 - binary_accuracy: 0.9628 - val_loss: 0.1647 - val_binary_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.1017 - binary_accuracy: 0.9636 - val_loss: 0.1654 - val_binary_accuracy: 0.9452\n",
      "Epoch 28/100\n",
      "184800/184800 [==============================] - 90s 488us/step - loss: 0.0992 - binary_accuracy: 0.9640 - val_loss: 0.1667 - val_binary_accuracy: 0.9459\n",
      "Epoch 29/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0983 - binary_accuracy: 0.9644 - val_loss: 0.1678 - val_binary_accuracy: 0.9454\n",
      "Epoch 30/100\n",
      "184800/184800 [==============================] - 90s 484us/step - loss: 0.0974 - binary_accuracy: 0.9648 - val_loss: 0.1636 - val_binary_accuracy: 0.9460\n",
      "Epoch 31/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0960 - binary_accuracy: 0.9654 - val_loss: 0.1648 - val_binary_accuracy: 0.9466\n",
      "Epoch 32/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0960 - binary_accuracy: 0.9645 - val_loss: 0.1632 - val_binary_accuracy: 0.9472\n",
      "Epoch 33/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0938 - binary_accuracy: 0.9661 - val_loss: 0.1629 - val_binary_accuracy: 0.9477\n",
      "Epoch 34/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0934 - binary_accuracy: 0.9664 - val_loss: 0.1654 - val_binary_accuracy: 0.9475\n",
      "Epoch 35/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0926 - binary_accuracy: 0.9666 - val_loss: 0.1633 - val_binary_accuracy: 0.9475\n",
      "Epoch 36/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0917 - binary_accuracy: 0.9667 - val_loss: 0.1641 - val_binary_accuracy: 0.9480\n",
      "Epoch 37/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0910 - binary_accuracy: 0.9669 - val_loss: 0.1658 - val_binary_accuracy: 0.9481\n",
      "Epoch 38/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0908 - binary_accuracy: 0.9669 - val_loss: 0.1647 - val_binary_accuracy: 0.9480\n",
      "Epoch 39/100\n",
      "184800/184800 [==============================] - 91s 491us/step - loss: 0.0896 - binary_accuracy: 0.9674 - val_loss: 0.1660 - val_binary_accuracy: 0.9480\n",
      "Epoch 40/100\n",
      "184800/184800 [==============================] - 89s 484us/step - loss: 0.0893 - binary_accuracy: 0.9677 - val_loss: 0.1651 - val_binary_accuracy: 0.9486\n",
      "Epoch 41/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0892 - binary_accuracy: 0.9678 - val_loss: 0.1653 - val_binary_accuracy: 0.9489\n",
      "Epoch 42/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0892 - binary_accuracy: 0.9681 - val_loss: 0.1657 - val_binary_accuracy: 0.9487\n",
      "Epoch 43/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0886 - binary_accuracy: 0.9684 - val_loss: 0.1659 - val_binary_accuracy: 0.9490\n",
      "Epoch 44/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0880 - binary_accuracy: 0.9683 - val_loss: 0.1653 - val_binary_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0871 - binary_accuracy: 0.9688 - val_loss: 0.1649 - val_binary_accuracy: 0.9488\n",
      "Epoch 46/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0872 - binary_accuracy: 0.9688 - val_loss: 0.1654 - val_binary_accuracy: 0.9490\n",
      "Epoch 47/100\n",
      "184800/184800 [==============================] - 85s 459us/step - loss: 0.0878 - binary_accuracy: 0.9683 - val_loss: 0.1660 - val_binary_accuracy: 0.9491\n",
      "Epoch 48/100\n",
      "184800/184800 [==============================] - 81s 439us/step - loss: 0.0865 - binary_accuracy: 0.9686 - val_loss: 0.1652 - val_binary_accuracy: 0.9493\n",
      "Epoch 49/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0868 - binary_accuracy: 0.9688 - val_loss: 0.1654 - val_binary_accuracy: 0.9491\n",
      "Epoch 50/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0863 - binary_accuracy: 0.9684 - val_loss: 0.1660 - val_binary_accuracy: 0.9491\n",
      "Epoch 51/100\n",
      "184800/184800 [==============================] - 80s 435us/step - loss: 0.0863 - binary_accuracy: 0.9689 - val_loss: 0.1653 - val_binary_accuracy: 0.9493\n",
      "Epoch 52/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0866 - binary_accuracy: 0.9685 - val_loss: 0.1654 - val_binary_accuracy: 0.9494\n",
      "Epoch 53/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0862 - binary_accuracy: 0.9684 - val_loss: 0.1655 - val_binary_accuracy: 0.9492\n",
      "Epoch 54/100\n",
      "184800/184800 [==============================] - 80s 436us/step - loss: 0.0862 - binary_accuracy: 0.9688 - val_loss: 0.1658 - val_binary_accuracy: 0.9494\n",
      "Epoch 55/100\n",
      "184800/184800 [==============================] - 81s 440us/step - loss: 0.0851 - binary_accuracy: 0.9691 - val_loss: 0.1652 - val_binary_accuracy: 0.9493\n",
      "Epoch 56/100\n",
      "184800/184800 [==============================] - 82s 441us/step - loss: 0.0852 - binary_accuracy: 0.9692 - val_loss: 0.1656 - val_binary_accuracy: 0.9493\n",
      "Epoch 57/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0858 - binary_accuracy: 0.9690 - val_loss: 0.1654 - val_binary_accuracy: 0.9493\n",
      "Epoch 58/100\n",
      "184800/184800 [==============================] - 85s 462us/step - loss: 0.0856 - binary_accuracy: 0.9689 - val_loss: 0.1657 - val_binary_accuracy: 0.9493\n",
      "Epoch 59/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0848 - binary_accuracy: 0.9691 - val_loss: 0.1662 - val_binary_accuracy: 0.9493\n",
      "Epoch 60/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0864 - binary_accuracy: 0.9686 - val_loss: 0.1662 - val_binary_accuracy: 0.9491\n",
      "Epoch 61/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0855 - binary_accuracy: 0.9693 - val_loss: 0.1656 - val_binary_accuracy: 0.9493\n",
      "Epoch 62/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0857 - binary_accuracy: 0.9689 - val_loss: 0.1656 - val_binary_accuracy: 0.9493\n",
      "Epoch 63/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0844 - binary_accuracy: 0.9697 - val_loss: 0.1658 - val_binary_accuracy: 0.9494\n",
      "Epoch 64/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0856 - binary_accuracy: 0.9696 - val_loss: 0.1658 - val_binary_accuracy: 0.9492\n",
      "Epoch 65/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0850 - binary_accuracy: 0.9690 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 66/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0853 - binary_accuracy: 0.9695 - val_loss: 0.1658 - val_binary_accuracy: 0.9493\n",
      "Epoch 67/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0849 - binary_accuracy: 0.9698 - val_loss: 0.1654 - val_binary_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0849 - binary_accuracy: 0.9692 - val_loss: 0.1656 - val_binary_accuracy: 0.9495\n",
      "Epoch 69/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0850 - binary_accuracy: 0.9696 - val_loss: 0.1663 - val_binary_accuracy: 0.9491\n",
      "Epoch 70/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0859 - binary_accuracy: 0.9690 - val_loss: 0.1658 - val_binary_accuracy: 0.9493\n",
      "Epoch 71/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0849 - binary_accuracy: 0.9694 - val_loss: 0.1660 - val_binary_accuracy: 0.9493\n",
      "Epoch 72/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0856 - binary_accuracy: 0.9687 - val_loss: 0.1658 - val_binary_accuracy: 0.9492\n",
      "Epoch 73/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0853 - binary_accuracy: 0.9691 - val_loss: 0.1660 - val_binary_accuracy: 0.9493\n",
      "Epoch 74/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0850 - binary_accuracy: 0.9690 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 75/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0851 - binary_accuracy: 0.9690 - val_loss: 0.1659 - val_binary_accuracy: 0.9493\n",
      "Epoch 76/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0848 - binary_accuracy: 0.9691 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0857 - binary_accuracy: 0.9687 - val_loss: 0.1662 - val_binary_accuracy: 0.9493\n",
      "Epoch 78/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0851 - binary_accuracy: 0.9690 - val_loss: 0.1660 - val_binary_accuracy: 0.9494\n",
      "Epoch 79/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0858 - binary_accuracy: 0.9689 - val_loss: 0.1660 - val_binary_accuracy: 0.9494\n",
      "Epoch 80/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0851 - binary_accuracy: 0.9691 - val_loss: 0.1661 - val_binary_accuracy: 0.9493\n",
      "Epoch 81/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0849 - binary_accuracy: 0.9695 - val_loss: 0.1662 - val_binary_accuracy: 0.9494\n",
      "Epoch 82/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0859 - binary_accuracy: 0.9694 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 83/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0846 - binary_accuracy: 0.9693 - val_loss: 0.1658 - val_binary_accuracy: 0.9494\n",
      "Epoch 84/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0852 - binary_accuracy: 0.9694 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 85/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0849 - binary_accuracy: 0.9691 - val_loss: 0.1660 - val_binary_accuracy: 0.9494\n",
      "Epoch 86/100\n",
      "184800/184800 [==============================] - 80s 435us/step - loss: 0.0845 - binary_accuracy: 0.9693 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 87/100\n",
      "184800/184800 [==============================] - 80s 434us/step - loss: 0.0847 - binary_accuracy: 0.9697 - val_loss: 0.1661 - val_binary_accuracy: 0.9493\n",
      "Epoch 88/100\n",
      "184800/184800 [==============================] - 80s 435us/step - loss: 0.0843 - binary_accuracy: 0.9696 - val_loss: 0.1659 - val_binary_accuracy: 0.9494\n",
      "Epoch 89/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0848 - binary_accuracy: 0.9694 - val_loss: 0.1659 - val_binary_accuracy: 0.9493\n",
      "Epoch 90/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0845 - binary_accuracy: 0.9693 - val_loss: 0.1660 - val_binary_accuracy: 0.9492\n",
      "Epoch 91/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0842 - binary_accuracy: 0.9692 - val_loss: 0.1659 - val_binary_accuracy: 0.9493\n",
      "Epoch 92/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0847 - binary_accuracy: 0.9694 - val_loss: 0.1660 - val_binary_accuracy: 0.9493\n",
      "Epoch 93/100\n",
      "184800/184800 [==============================] - 81s 436us/step - loss: 0.0858 - binary_accuracy: 0.9689 - val_loss: 0.1660 - val_binary_accuracy: 0.9493\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0838 - binary_accuracy: 0.9697 - val_loss: 0.1660 - val_binary_accuracy: 0.9494\n",
      "Epoch 95/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0854 - binary_accuracy: 0.9691 - val_loss: 0.1660 - val_binary_accuracy: 0.9493\n",
      "Epoch 96/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0854 - binary_accuracy: 0.9692 - val_loss: 0.1661 - val_binary_accuracy: 0.9493\n",
      "Epoch 97/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0850 - binary_accuracy: 0.9691 - val_loss: 0.1659 - val_binary_accuracy: 0.9493\n",
      "Epoch 98/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0846 - binary_accuracy: 0.9694 - val_loss: 0.1660 - val_binary_accuracy: 0.9494\n",
      "184800/184800 [==============================] - 27s 146us/step\n",
      "(184800,)\n",
      "(184800,)\n",
      "61600/61600 [==============================] - 9s 144us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "61600/61600 [==============================] - 9s 148us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "(61600, 41, 4) (184800, 41, 4)\n",
      "(184800, 41, 4) (61600, 41, 4) (61600, 41, 4)\n",
      "Train on 184800 samples, validate on 61600 samples\n",
      "Epoch 1/100\n",
      "184800/184800 [==============================] - 81s 440us/step - loss: 0.2230 - binary_accuracy: 0.9116 - val_loss: 0.2298 - val_binary_accuracy: 0.9159\n",
      "Epoch 2/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.1866 - binary_accuracy: 0.9275 - val_loss: 0.2312 - val_binary_accuracy: 0.9134\n",
      "Epoch 3/100\n",
      "184800/184800 [==============================] - 79s 427us/step - loss: 0.1770 - binary_accuracy: 0.9316 - val_loss: 0.2130 - val_binary_accuracy: 0.9248\n",
      "Epoch 4/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.1697 - binary_accuracy: 0.9349 - val_loss: 0.1992 - val_binary_accuracy: 0.9297\n",
      "Epoch 5/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.1631 - binary_accuracy: 0.9373 - val_loss: 0.2057 - val_binary_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.1578 - binary_accuracy: 0.9396 - val_loss: 0.1905 - val_binary_accuracy: 0.9330\n",
      "Epoch 7/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.1533 - binary_accuracy: 0.9416 - val_loss: 0.1894 - val_binary_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.1474 - binary_accuracy: 0.9443 - val_loss: 0.1903 - val_binary_accuracy: 0.9331\n",
      "Epoch 9/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.1441 - binary_accuracy: 0.9450 - val_loss: 0.1978 - val_binary_accuracy: 0.9324\n",
      "Epoch 10/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.1398 - binary_accuracy: 0.9471 - val_loss: 0.1938 - val_binary_accuracy: 0.9333\n",
      "Epoch 11/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.1349 - binary_accuracy: 0.9494 - val_loss: 0.1974 - val_binary_accuracy: 0.9334\n",
      "Epoch 12/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.1295 - binary_accuracy: 0.9520 - val_loss: 0.1891 - val_binary_accuracy: 0.9351\n",
      "Epoch 13/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.1250 - binary_accuracy: 0.9538 - val_loss: 0.1847 - val_binary_accuracy: 0.9383\n",
      "Epoch 14/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.1206 - binary_accuracy: 0.9554 - val_loss: 0.1844 - val_binary_accuracy: 0.9376\n",
      "Epoch 15/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.1165 - binary_accuracy: 0.9573 - val_loss: 0.1874 - val_binary_accuracy: 0.9370\n",
      "Epoch 16/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.1134 - binary_accuracy: 0.9583 - val_loss: 0.1879 - val_binary_accuracy: 0.9393\n",
      "Epoch 17/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.1099 - binary_accuracy: 0.9601 - val_loss: 0.1919 - val_binary_accuracy: 0.9386\n",
      "Epoch 18/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.1064 - binary_accuracy: 0.9609 - val_loss: 0.1868 - val_binary_accuracy: 0.9411\n",
      "Epoch 19/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.1029 - binary_accuracy: 0.9623 - val_loss: 0.1926 - val_binary_accuracy: 0.9388\n",
      "Epoch 20/100\n",
      "184800/184800 [==============================] - 79s 427us/step - loss: 0.1016 - binary_accuracy: 0.9628 - val_loss: 0.1861 - val_binary_accuracy: 0.9406\n",
      "Epoch 21/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0981 - binary_accuracy: 0.9649 - val_loss: 0.1864 - val_binary_accuracy: 0.9423\n",
      "Epoch 22/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0959 - binary_accuracy: 0.9656 - val_loss: 0.1862 - val_binary_accuracy: 0.9425\n",
      "Epoch 23/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.0948 - binary_accuracy: 0.9657 - val_loss: 0.1942 - val_binary_accuracy: 0.9403\n",
      "Epoch 24/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.0922 - binary_accuracy: 0.9665 - val_loss: 0.1920 - val_binary_accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0905 - binary_accuracy: 0.9673 - val_loss: 0.1895 - val_binary_accuracy: 0.9426\n",
      "Epoch 26/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0883 - binary_accuracy: 0.9682 - val_loss: 0.1906 - val_binary_accuracy: 0.9427\n",
      "Epoch 27/100\n",
      "184800/184800 [==============================] - 82s 446us/step - loss: 0.0864 - binary_accuracy: 0.9690 - val_loss: 0.1857 - val_binary_accuracy: 0.9453\n",
      "Epoch 28/100\n",
      "184800/184800 [==============================] - 84s 452us/step - loss: 0.0853 - binary_accuracy: 0.9695 - val_loss: 0.1904 - val_binary_accuracy: 0.9440\n",
      "Epoch 29/100\n",
      "184800/184800 [==============================] - 83s 450us/step - loss: 0.0844 - binary_accuracy: 0.9696 - val_loss: 0.1913 - val_binary_accuracy: 0.9443\n",
      "Epoch 30/100\n",
      "184800/184800 [==============================] - 83s 449us/step - loss: 0.0830 - binary_accuracy: 0.9699 - val_loss: 0.1914 - val_binary_accuracy: 0.9443\n",
      "Epoch 31/100\n",
      "184800/184800 [==============================] - 83s 449us/step - loss: 0.0818 - binary_accuracy: 0.9704 - val_loss: 0.1904 - val_binary_accuracy: 0.9447\n",
      "Epoch 32/100\n",
      "184800/184800 [==============================] - 83s 452us/step - loss: 0.0808 - binary_accuracy: 0.9712 - val_loss: 0.1930 - val_binary_accuracy: 0.9445\n",
      "Epoch 33/100\n",
      "184800/184800 [==============================] - 84s 452us/step - loss: 0.0797 - binary_accuracy: 0.9717 - val_loss: 0.1934 - val_binary_accuracy: 0.9447\n",
      "Epoch 34/100\n",
      "184800/184800 [==============================] - 83s 451us/step - loss: 0.0785 - binary_accuracy: 0.9720 - val_loss: 0.1920 - val_binary_accuracy: 0.9453\n",
      "Epoch 35/100\n",
      "184800/184800 [==============================] - 84s 452us/step - loss: 0.0791 - binary_accuracy: 0.9717 - val_loss: 0.1933 - val_binary_accuracy: 0.9452\n",
      "Epoch 36/100\n",
      "184800/184800 [==============================] - 84s 453us/step - loss: 0.0782 - binary_accuracy: 0.9721 - val_loss: 0.1951 - val_binary_accuracy: 0.9448\n",
      "Epoch 37/100\n",
      "184800/184800 [==============================] - 83s 451us/step - loss: 0.0774 - binary_accuracy: 0.9722 - val_loss: 0.1914 - val_binary_accuracy: 0.9457\n",
      "Epoch 38/100\n",
      "184800/184800 [==============================] - 83s 450us/step - loss: 0.0765 - binary_accuracy: 0.9727 - val_loss: 0.1934 - val_binary_accuracy: 0.9453\n",
      "Epoch 39/100\n",
      "184800/184800 [==============================] - 83s 451us/step - loss: 0.0763 - binary_accuracy: 0.9729 - val_loss: 0.1975 - val_binary_accuracy: 0.9448\n",
      "Epoch 40/100\n",
      "184800/184800 [==============================] - 84s 452us/step - loss: 0.0755 - binary_accuracy: 0.9731 - val_loss: 0.1944 - val_binary_accuracy: 0.9457\n",
      "Epoch 41/100\n",
      "184800/184800 [==============================] - 83s 451us/step - loss: 0.0753 - binary_accuracy: 0.9732 - val_loss: 0.1949 - val_binary_accuracy: 0.9460\n",
      "Epoch 42/100\n",
      "184800/184800 [==============================] - 83s 450us/step - loss: 0.0746 - binary_accuracy: 0.9732 - val_loss: 0.1961 - val_binary_accuracy: 0.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "184800/184800 [==============================] - 83s 448us/step - loss: 0.0744 - binary_accuracy: 0.9735 - val_loss: 0.1960 - val_binary_accuracy: 0.9458\n",
      "Epoch 44/100\n",
      "184800/184800 [==============================] - 81s 439us/step - loss: 0.0745 - binary_accuracy: 0.9734 - val_loss: 0.1955 - val_binary_accuracy: 0.9459\n",
      "Epoch 45/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0736 - binary_accuracy: 0.9735 - val_loss: 0.1957 - val_binary_accuracy: 0.9458\n",
      "Epoch 46/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0738 - binary_accuracy: 0.9740 - val_loss: 0.1966 - val_binary_accuracy: 0.9458\n",
      "Epoch 47/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.0737 - binary_accuracy: 0.9741 - val_loss: 0.1961 - val_binary_accuracy: 0.9462\n",
      "Epoch 48/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0733 - binary_accuracy: 0.9739 - val_loss: 0.1973 - val_binary_accuracy: 0.9461\n",
      "Epoch 49/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0730 - binary_accuracy: 0.9742 - val_loss: 0.1963 - val_binary_accuracy: 0.9461\n",
      "Epoch 50/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0723 - binary_accuracy: 0.9743 - val_loss: 0.1972 - val_binary_accuracy: 0.9460\n",
      "Epoch 51/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0726 - binary_accuracy: 0.9739 - val_loss: 0.1970 - val_binary_accuracy: 0.9462\n",
      "Epoch 52/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0724 - binary_accuracy: 0.9744 - val_loss: 0.1965 - val_binary_accuracy: 0.9461\n",
      "Epoch 53/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0714 - binary_accuracy: 0.9748 - val_loss: 0.1965 - val_binary_accuracy: 0.9464\n",
      "Epoch 54/100\n",
      "184800/184800 [==============================] - 80s 433us/step - loss: 0.0718 - binary_accuracy: 0.9747 - val_loss: 0.1968 - val_binary_accuracy: 0.9465\n",
      "Epoch 55/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0713 - binary_accuracy: 0.9744 - val_loss: 0.1968 - val_binary_accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0715 - binary_accuracy: 0.9744 - val_loss: 0.1965 - val_binary_accuracy: 0.9463\n",
      "Epoch 57/100\n",
      "184800/184800 [==============================] - 79s 427us/step - loss: 0.0727 - binary_accuracy: 0.9744 - val_loss: 0.1967 - val_binary_accuracy: 0.9463\n",
      "Epoch 58/100\n",
      "184800/184800 [==============================] - 79s 427us/step - loss: 0.0713 - binary_accuracy: 0.9744 - val_loss: 0.1978 - val_binary_accuracy: 0.9463\n",
      "Epoch 59/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0719 - binary_accuracy: 0.9744 - val_loss: 0.1971 - val_binary_accuracy: 0.9463\n",
      "Epoch 60/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0718 - binary_accuracy: 0.9745 - val_loss: 0.1975 - val_binary_accuracy: 0.9461\n",
      "Epoch 61/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0711 - binary_accuracy: 0.9747 - val_loss: 0.1966 - val_binary_accuracy: 0.9464\n",
      "Epoch 62/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0712 - binary_accuracy: 0.9748 - val_loss: 0.1973 - val_binary_accuracy: 0.9464\n",
      "Epoch 63/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0713 - binary_accuracy: 0.9746 - val_loss: 0.1968 - val_binary_accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0714 - binary_accuracy: 0.9750 - val_loss: 0.1972 - val_binary_accuracy: 0.9463\n",
      "Epoch 65/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0712 - binary_accuracy: 0.9749 - val_loss: 0.1975 - val_binary_accuracy: 0.9462\n",
      "Epoch 66/100\n",
      "184800/184800 [==============================] - 80s 430us/step - loss: 0.0711 - binary_accuracy: 0.9748 - val_loss: 0.1971 - val_binary_accuracy: 0.9463\n",
      "Epoch 67/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0715 - binary_accuracy: 0.9747 - val_loss: 0.1970 - val_binary_accuracy: 0.9464\n",
      "Epoch 68/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0703 - binary_accuracy: 0.9751 - val_loss: 0.1975 - val_binary_accuracy: 0.9464\n",
      "Epoch 69/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0709 - binary_accuracy: 0.9747 - val_loss: 0.1979 - val_binary_accuracy: 0.9464\n",
      "Epoch 70/100\n",
      "184800/184800 [==============================] - 79s 430us/step - loss: 0.0711 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9463\n",
      "Epoch 71/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0711 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9464\n",
      "Epoch 72/100\n",
      "184800/184800 [==============================] - 80s 432us/step - loss: 0.0710 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9464\n",
      "Epoch 73/100\n",
      "184800/184800 [==============================] - 80s 431us/step - loss: 0.0711 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9463\n",
      "Epoch 74/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.0712 - binary_accuracy: 0.9745 - val_loss: 0.1981 - val_binary_accuracy: 0.9464\n",
      "Epoch 75/100\n",
      "184800/184800 [==============================] - 79s 429us/step - loss: 0.0707 - binary_accuracy: 0.9749 - val_loss: 0.1980 - val_binary_accuracy: 0.9463\n",
      "Epoch 76/100\n",
      "184800/184800 [==============================] - 79s 428us/step - loss: 0.0708 - binary_accuracy: 0.9750 - val_loss: 0.1982 - val_binary_accuracy: 0.9464\n",
      "Epoch 77/100\n",
      "184800/184800 [==============================] - 84s 454us/step - loss: 0.0713 - binary_accuracy: 0.9748 - val_loss: 0.1980 - val_binary_accuracy: 0.9463\n",
      "Epoch 78/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0705 - binary_accuracy: 0.9751 - val_loss: 0.1978 - val_binary_accuracy: 0.9464\n",
      "Epoch 79/100\n",
      "184800/184800 [==============================] - 90s 486us/step - loss: 0.0708 - binary_accuracy: 0.9748 - val_loss: 0.1978 - val_binary_accuracy: 0.9465\n",
      "Epoch 80/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0715 - binary_accuracy: 0.9750 - val_loss: 0.1976 - val_binary_accuracy: 0.9463\n",
      "Epoch 81/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0710 - binary_accuracy: 0.9745 - val_loss: 0.1978 - val_binary_accuracy: 0.9465\n",
      "Epoch 82/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.0717 - binary_accuracy: 0.9745 - val_loss: 0.1979 - val_binary_accuracy: 0.9464\n",
      "Epoch 83/100\n",
      "184800/184800 [==============================] - 89s 483us/step - loss: 0.0706 - binary_accuracy: 0.9747 - val_loss: 0.1977 - val_binary_accuracy: 0.9463\n",
      "Epoch 84/100\n",
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.0707 - binary_accuracy: 0.9750 - val_loss: 0.1980 - val_binary_accuracy: 0.9466\n",
      "Epoch 85/100\n",
      "184800/184800 [==============================] - 82s 442us/step - loss: 0.0703 - binary_accuracy: 0.9749 - val_loss: 0.1979 - val_binary_accuracy: 0.9463\n",
      "Epoch 86/100\n",
      "184800/184800 [==============================] - 85s 459us/step - loss: 0.0712 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9463\n",
      "Epoch 87/100\n",
      "184800/184800 [==============================] - 89s 481us/step - loss: 0.0703 - binary_accuracy: 0.9751 - val_loss: 0.1980 - val_binary_accuracy: 0.9464\n",
      "Epoch 88/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0709 - binary_accuracy: 0.9747 - val_loss: 0.1975 - val_binary_accuracy: 0.9465\n",
      "Epoch 89/100\n",
      "184800/184800 [==============================] - 81s 437us/step - loss: 0.0709 - binary_accuracy: 0.9750 - val_loss: 0.1975 - val_binary_accuracy: 0.9464\n",
      "Epoch 90/100\n",
      "184800/184800 [==============================] - 88s 478us/step - loss: 0.0708 - binary_accuracy: 0.9748 - val_loss: 0.1979 - val_binary_accuracy: 0.9463\n",
      "Epoch 91/100\n",
      "184800/184800 [==============================] - 89s 479us/step - loss: 0.0704 - binary_accuracy: 0.9753 - val_loss: 0.1976 - val_binary_accuracy: 0.9464\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184800/184800 [==============================] - 89s 480us/step - loss: 0.0703 - binary_accuracy: 0.9750 - val_loss: 0.1980 - val_binary_accuracy: 0.9464\n",
      "Epoch 93/100\n",
      "184800/184800 [==============================] - 90s 485us/step - loss: 0.0710 - binary_accuracy: 0.9750 - val_loss: 0.1977 - val_binary_accuracy: 0.9464\n",
      "Epoch 94/100\n",
      "184800/184800 [==============================] - 89s 482us/step - loss: 0.0711 - binary_accuracy: 0.9747 - val_loss: 0.1979 - val_binary_accuracy: 0.9464\n",
      "Epoch 95/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0702 - binary_accuracy: 0.9747 - val_loss: 0.1978 - val_binary_accuracy: 0.9464\n",
      "Epoch 96/100\n",
      "184800/184800 [==============================] - 83s 448us/step - loss: 0.0709 - binary_accuracy: 0.9745 - val_loss: 0.1977 - val_binary_accuracy: 0.9463\n",
      "Epoch 97/100\n",
      "184800/184800 [==============================] - 84s 455us/step - loss: 0.0698 - binary_accuracy: 0.9751 - val_loss: 0.1977 - val_binary_accuracy: 0.9464\n",
      "Epoch 98/100\n",
      "184800/184800 [==============================] - 83s 447us/step - loss: 0.0709 - binary_accuracy: 0.9748 - val_loss: 0.1975 - val_binary_accuracy: 0.9464\n",
      "Epoch 99/100\n",
      "184800/184800 [==============================] - 82s 441us/step - loss: 0.0703 - binary_accuracy: 0.9749 - val_loss: 0.1978 - val_binary_accuracy: 0.9463\n",
      "Epoch 100/100\n",
      "184800/184800 [==============================] - 82s 441us/step - loss: 0.0704 - binary_accuracy: 0.9751 - val_loss: 0.1978 - val_binary_accuracy: 0.9463\n",
      "184800/184800 [==============================] - 28s 152us/step\n",
      "(184800,)\n",
      "(184800,)\n",
      "61600/61600 [==============================] - 10s 162us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "61600/61600 [==============================] - 10s 166us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "(61600, 41, 4) (184800, 41, 4)\n",
      "(184800, 41, 4) (61600, 41, 4) (61600, 41, 4)\n",
      "Train on 184800 samples, validate on 61600 samples\n",
      "Epoch 1/100\n",
      "184800/184800 [==============================] - 90s 487us/step - loss: 0.2090 - binary_accuracy: 0.9147 - val_loss: 0.3668 - val_binary_accuracy: 0.8462\n",
      "Epoch 2/100\n",
      "184800/184800 [==============================] - 88s 474us/step - loss: 0.1716 - binary_accuracy: 0.9313 - val_loss: 0.3126 - val_binary_accuracy: 0.8759\n",
      "Epoch 3/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.1615 - binary_accuracy: 0.9353 - val_loss: 0.3215 - val_binary_accuracy: 0.8765\n",
      "Epoch 4/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.1538 - binary_accuracy: 0.9391 - val_loss: 0.3030 - val_binary_accuracy: 0.8813\n",
      "Epoch 5/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.1470 - binary_accuracy: 0.9418 - val_loss: 0.3433 - val_binary_accuracy: 0.8709\n",
      "Epoch 6/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1403 - binary_accuracy: 0.9447 - val_loss: 0.3099 - val_binary_accuracy: 0.8811\n",
      "Epoch 7/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1363 - binary_accuracy: 0.9470 - val_loss: 0.2950 - val_binary_accuracy: 0.8918\n",
      "Epoch 8/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.1310 - binary_accuracy: 0.9485 - val_loss: 0.3034 - val_binary_accuracy: 0.8953\n",
      "Epoch 9/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.1265 - binary_accuracy: 0.9507 - val_loss: 0.2891 - val_binary_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.1218 - binary_accuracy: 0.9531 - val_loss: 0.3146 - val_binary_accuracy: 0.8884\n",
      "Epoch 11/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.1168 - binary_accuracy: 0.9548 - val_loss: 0.3683 - val_binary_accuracy: 0.8780\n",
      "Epoch 12/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1125 - binary_accuracy: 0.9568 - val_loss: 0.2993 - val_binary_accuracy: 0.8974\n",
      "Epoch 13/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1076 - binary_accuracy: 0.9592 - val_loss: 0.2916 - val_binary_accuracy: 0.9010\n",
      "Epoch 14/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1024 - binary_accuracy: 0.9616 - val_loss: 0.3113 - val_binary_accuracy: 0.8938\n",
      "Epoch 15/100\n",
      "184800/184800 [==============================] - 87s 473us/step - loss: 0.0990 - binary_accuracy: 0.9624 - val_loss: 0.3163 - val_binary_accuracy: 0.8941\n",
      "Epoch 16/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0949 - binary_accuracy: 0.9647 - val_loss: 0.3184 - val_binary_accuracy: 0.8963\n",
      "Epoch 17/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0910 - binary_accuracy: 0.9664 - val_loss: 0.3054 - val_binary_accuracy: 0.9010\n",
      "Epoch 18/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0882 - binary_accuracy: 0.9674 - val_loss: 0.3311 - val_binary_accuracy: 0.8997\n",
      "Epoch 19/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0850 - binary_accuracy: 0.9683 - val_loss: 0.3324 - val_binary_accuracy: 0.8980\n",
      "Epoch 20/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0834 - binary_accuracy: 0.9689 - val_loss: 0.3121 - val_binary_accuracy: 0.9028\n",
      "Epoch 21/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0799 - binary_accuracy: 0.9702 - val_loss: 0.3242 - val_binary_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0780 - binary_accuracy: 0.9712 - val_loss: 0.3420 - val_binary_accuracy: 0.8987\n",
      "Epoch 23/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0753 - binary_accuracy: 0.9719 - val_loss: 0.3227 - val_binary_accuracy: 0.9053\n",
      "Epoch 24/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0739 - binary_accuracy: 0.9730 - val_loss: 0.3290 - val_binary_accuracy: 0.9054\n",
      "Epoch 25/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0722 - binary_accuracy: 0.9736 - val_loss: 0.3331 - val_binary_accuracy: 0.9029\n",
      "Epoch 26/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0712 - binary_accuracy: 0.9740 - val_loss: 0.3380 - val_binary_accuracy: 0.9019\n",
      "Epoch 27/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0683 - binary_accuracy: 0.9751 - val_loss: 0.3380 - val_binary_accuracy: 0.9042\n",
      "Epoch 28/100\n",
      "184800/184800 [==============================] - 82s 444us/step - loss: 0.0680 - binary_accuracy: 0.9754 - val_loss: 0.3396 - val_binary_accuracy: 0.9036\n",
      "Epoch 29/100\n",
      "184800/184800 [==============================] - 77s 416us/step - loss: 0.0672 - binary_accuracy: 0.9751 - val_loss: 0.3397 - val_binary_accuracy: 0.9046\n",
      "Epoch 30/100\n",
      "184800/184800 [==============================] - 78s 421us/step - loss: 0.0653 - binary_accuracy: 0.9761 - val_loss: 0.3383 - val_binary_accuracy: 0.9062\n",
      "Epoch 31/100\n",
      "184800/184800 [==============================] - 85s 461us/step - loss: 0.0648 - binary_accuracy: 0.9762 - val_loss: 0.3394 - val_binary_accuracy: 0.9061\n",
      "Epoch 32/100\n",
      "184800/184800 [==============================] - 90s 489us/step - loss: 0.0626 - binary_accuracy: 0.9773 - val_loss: 0.3380 - val_binary_accuracy: 0.9078\n",
      "Epoch 33/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0623 - binary_accuracy: 0.9774 - val_loss: 0.3416 - val_binary_accuracy: 0.9059\n",
      "Epoch 34/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0606 - binary_accuracy: 0.9782 - val_loss: 0.3485 - val_binary_accuracy: 0.9050\n",
      "Epoch 35/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0606 - binary_accuracy: 0.9781 - val_loss: 0.3458 - val_binary_accuracy: 0.9075\n",
      "Epoch 36/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0600 - binary_accuracy: 0.9784 - val_loss: 0.3479 - val_binary_accuracy: 0.9071\n",
      "Epoch 37/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0595 - binary_accuracy: 0.9784 - val_loss: 0.3485 - val_binary_accuracy: 0.9079\n",
      "Epoch 38/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0588 - binary_accuracy: 0.9786 - val_loss: 0.3481 - val_binary_accuracy: 0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0591 - binary_accuracy: 0.9786 - val_loss: 0.3461 - val_binary_accuracy: 0.9081\n",
      "Epoch 40/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0589 - binary_accuracy: 0.9783 - val_loss: 0.3513 - val_binary_accuracy: 0.9066\n",
      "Epoch 41/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0572 - binary_accuracy: 0.9791 - val_loss: 0.3536 - val_binary_accuracy: 0.9065\n",
      "Epoch 42/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0574 - binary_accuracy: 0.9790 - val_loss: 0.3546 - val_binary_accuracy: 0.9071\n",
      "Epoch 43/100\n",
      "184800/184800 [==============================] - 87s 473us/step - loss: 0.0576 - binary_accuracy: 0.9791 - val_loss: 0.3514 - val_binary_accuracy: 0.9083\n",
      "Epoch 44/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0574 - binary_accuracy: 0.9791 - val_loss: 0.3546 - val_binary_accuracy: 0.9078\n",
      "Epoch 45/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0568 - binary_accuracy: 0.9795 - val_loss: 0.3583 - val_binary_accuracy: 0.9061\n",
      "Epoch 46/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0558 - binary_accuracy: 0.9801 - val_loss: 0.3555 - val_binary_accuracy: 0.9078\n",
      "Epoch 47/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0556 - binary_accuracy: 0.9801 - val_loss: 0.3530 - val_binary_accuracy: 0.9086\n",
      "Epoch 48/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0558 - binary_accuracy: 0.9797 - val_loss: 0.3547 - val_binary_accuracy: 0.9082\n",
      "Epoch 49/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0560 - binary_accuracy: 0.9800 - val_loss: 0.3542 - val_binary_accuracy: 0.9076\n",
      "Epoch 50/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0559 - binary_accuracy: 0.9802 - val_loss: 0.3609 - val_binary_accuracy: 0.9071\n",
      "Epoch 51/100\n",
      "184800/184800 [==============================] - 87s 473us/step - loss: 0.0555 - binary_accuracy: 0.9800 - val_loss: 0.3590 - val_binary_accuracy: 0.9078\n",
      "Epoch 52/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0558 - binary_accuracy: 0.9798 - val_loss: 0.3579 - val_binary_accuracy: 0.9070\n",
      "Epoch 53/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0548 - binary_accuracy: 0.9802 - val_loss: 0.3591 - val_binary_accuracy: 0.9076\n",
      "Epoch 54/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0562 - binary_accuracy: 0.9793 - val_loss: 0.3550 - val_binary_accuracy: 0.9083\n",
      "Epoch 55/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0546 - binary_accuracy: 0.9804 - val_loss: 0.3580 - val_binary_accuracy: 0.9072\n",
      "Epoch 56/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0540 - binary_accuracy: 0.9806 - val_loss: 0.3580 - val_binary_accuracy: 0.9081\n",
      "Epoch 57/100\n",
      "184800/184800 [==============================] - 85s 462us/step - loss: 0.0548 - binary_accuracy: 0.9803 - val_loss: 0.3567 - val_binary_accuracy: 0.9085\n",
      "Epoch 58/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0549 - binary_accuracy: 0.9802 - val_loss: 0.3577 - val_binary_accuracy: 0.9080\n",
      "Epoch 59/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0551 - binary_accuracy: 0.9801 - val_loss: 0.3586 - val_binary_accuracy: 0.9077\n",
      "Epoch 60/100\n",
      "184800/184800 [==============================] - 88s 474us/step - loss: 0.0541 - binary_accuracy: 0.9804 - val_loss: 0.3605 - val_binary_accuracy: 0.9073\n",
      "Epoch 61/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0545 - binary_accuracy: 0.9805 - val_loss: 0.3593 - val_binary_accuracy: 0.9081\n",
      "Epoch 62/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0547 - binary_accuracy: 0.9805 - val_loss: 0.3590 - val_binary_accuracy: 0.9077\n",
      "Epoch 63/100\n",
      "184800/184800 [==============================] - 87s 473us/step - loss: 0.0541 - binary_accuracy: 0.9804 - val_loss: 0.3589 - val_binary_accuracy: 0.9075\n",
      "Epoch 64/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0546 - binary_accuracy: 0.9801 - val_loss: 0.3575 - val_binary_accuracy: 0.9082\n",
      "Epoch 65/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0548 - binary_accuracy: 0.9802 - val_loss: 0.3578 - val_binary_accuracy: 0.9082\n",
      "Epoch 66/100\n",
      "184800/184800 [==============================] - 87s 473us/step - loss: 0.0547 - binary_accuracy: 0.9803 - val_loss: 0.3597 - val_binary_accuracy: 0.9077\n",
      "Epoch 67/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0545 - binary_accuracy: 0.9800 - val_loss: 0.3585 - val_binary_accuracy: 0.9080\n",
      "Epoch 68/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0541 - binary_accuracy: 0.9805 - val_loss: 0.3590 - val_binary_accuracy: 0.9081\n",
      "184800/184800 [==============================] - 29s 158us/step\n",
      "(184800,)\n",
      "(184800,)\n",
      "61600/61600 [==============================] - 10s 161us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "61600/61600 [==============================] - 10s 158us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "(61600, 41, 4) (184800, 41, 4)\n",
      "(184800, 41, 4) (61600, 41, 4) (61600, 41, 4)\n",
      "Train on 184800 samples, validate on 61600 samples\n",
      "Epoch 1/100\n",
      "184800/184800 [==============================] - 89s 479us/step - loss: 0.2320 - binary_accuracy: 0.9081 - val_loss: 0.1709 - val_binary_accuracy: 0.9322\n",
      "Epoch 2/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1932 - binary_accuracy: 0.9261 - val_loss: 0.1706 - val_binary_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.1842 - binary_accuracy: 0.9293 - val_loss: 0.1559 - val_binary_accuracy: 0.9359\n",
      "Epoch 4/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.1769 - binary_accuracy: 0.9323 - val_loss: 0.1717 - val_binary_accuracy: 0.9287\n",
      "Epoch 5/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1717 - binary_accuracy: 0.9341 - val_loss: 0.1525 - val_binary_accuracy: 0.9359\n",
      "Epoch 6/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1666 - binary_accuracy: 0.9362 - val_loss: 0.1527 - val_binary_accuracy: 0.9373\n",
      "Epoch 7/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1620 - binary_accuracy: 0.9373 - val_loss: 0.1605 - val_binary_accuracy: 0.9328\n",
      "Epoch 8/100\n",
      "184800/184800 [==============================] - 85s 462us/step - loss: 0.1583 - binary_accuracy: 0.9394 - val_loss: 0.1494 - val_binary_accuracy: 0.9371\n",
      "Epoch 9/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.1544 - binary_accuracy: 0.9405 - val_loss: 0.1446 - val_binary_accuracy: 0.9403\n",
      "Epoch 10/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1505 - binary_accuracy: 0.9425 - val_loss: 0.1528 - val_binary_accuracy: 0.9362\n",
      "Epoch 11/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1458 - binary_accuracy: 0.9445 - val_loss: 0.1482 - val_binary_accuracy: 0.9388\n",
      "Epoch 12/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.1415 - binary_accuracy: 0.9462 - val_loss: 0.1455 - val_binary_accuracy: 0.9407\n",
      "Epoch 13/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.1365 - binary_accuracy: 0.9483 - val_loss: 0.1387 - val_binary_accuracy: 0.9427\n",
      "Epoch 14/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1333 - binary_accuracy: 0.9489 - val_loss: 0.1319 - val_binary_accuracy: 0.9477\n",
      "Epoch 15/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.1287 - binary_accuracy: 0.9513 - val_loss: 0.1331 - val_binary_accuracy: 0.9470\n",
      "Epoch 16/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.1259 - binary_accuracy: 0.9527 - val_loss: 0.1325 - val_binary_accuracy: 0.9468\n",
      "Epoch 17/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1223 - binary_accuracy: 0.9540 - val_loss: 0.1238 - val_binary_accuracy: 0.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1204 - binary_accuracy: 0.9547 - val_loss: 0.1280 - val_binary_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.1167 - binary_accuracy: 0.9565 - val_loss: 0.1316 - val_binary_accuracy: 0.9479\n",
      "Epoch 20/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.1139 - binary_accuracy: 0.9573 - val_loss: 0.1238 - val_binary_accuracy: 0.9523\n",
      "Epoch 21/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1115 - binary_accuracy: 0.9579 - val_loss: 0.1268 - val_binary_accuracy: 0.9519\n",
      "Epoch 22/100\n",
      "184800/184800 [==============================] - 85s 462us/step - loss: 0.1081 - binary_accuracy: 0.9591 - val_loss: 0.1291 - val_binary_accuracy: 0.9498\n",
      "Epoch 23/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1074 - binary_accuracy: 0.9594 - val_loss: 0.1216 - val_binary_accuracy: 0.9531\n",
      "Epoch 24/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1053 - binary_accuracy: 0.9604 - val_loss: 0.1221 - val_binary_accuracy: 0.9533\n",
      "Epoch 25/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1028 - binary_accuracy: 0.9616 - val_loss: 0.1221 - val_binary_accuracy: 0.9530\n",
      "Epoch 26/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1012 - binary_accuracy: 0.9625 - val_loss: 0.1216 - val_binary_accuracy: 0.9536\n",
      "Epoch 27/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.1005 - binary_accuracy: 0.9627 - val_loss: 0.1161 - val_binary_accuracy: 0.9558\n",
      "Epoch 28/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0987 - binary_accuracy: 0.9632 - val_loss: 0.1209 - val_binary_accuracy: 0.9546\n",
      "Epoch 29/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0979 - binary_accuracy: 0.9636 - val_loss: 0.1164 - val_binary_accuracy: 0.9567\n",
      "Epoch 30/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0955 - binary_accuracy: 0.9647 - val_loss: 0.1200 - val_binary_accuracy: 0.9555\n",
      "Epoch 31/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0947 - binary_accuracy: 0.9644 - val_loss: 0.1180 - val_binary_accuracy: 0.9563\n",
      "Epoch 32/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0930 - binary_accuracy: 0.9654 - val_loss: 0.1143 - val_binary_accuracy: 0.9580\n",
      "Epoch 33/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0926 - binary_accuracy: 0.9655 - val_loss: 0.1127 - val_binary_accuracy: 0.9585\n",
      "Epoch 34/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0919 - binary_accuracy: 0.9659 - val_loss: 0.1168 - val_binary_accuracy: 0.9578\n",
      "Epoch 35/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0912 - binary_accuracy: 0.9661 - val_loss: 0.1181 - val_binary_accuracy: 0.9568\n",
      "Epoch 36/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0909 - binary_accuracy: 0.9662 - val_loss: 0.1127 - val_binary_accuracy: 0.9584\n",
      "Epoch 37/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0905 - binary_accuracy: 0.9660 - val_loss: 0.1153 - val_binary_accuracy: 0.9576\n",
      "Epoch 38/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.0892 - binary_accuracy: 0.9669 - val_loss: 0.1132 - val_binary_accuracy: 0.9587\n",
      "Epoch 39/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0886 - binary_accuracy: 0.9671 - val_loss: 0.1137 - val_binary_accuracy: 0.9585\n",
      "Epoch 40/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0886 - binary_accuracy: 0.9671 - val_loss: 0.1143 - val_binary_accuracy: 0.9587\n",
      "Epoch 41/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0879 - binary_accuracy: 0.9670 - val_loss: 0.1117 - val_binary_accuracy: 0.9602\n",
      "Epoch 42/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.0879 - binary_accuracy: 0.9669 - val_loss: 0.1121 - val_binary_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0870 - binary_accuracy: 0.9677 - val_loss: 0.1132 - val_binary_accuracy: 0.9594\n",
      "Epoch 44/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0863 - binary_accuracy: 0.9685 - val_loss: 0.1134 - val_binary_accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0856 - binary_accuracy: 0.9684 - val_loss: 0.1123 - val_binary_accuracy: 0.9597\n",
      "Epoch 46/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0864 - binary_accuracy: 0.9681 - val_loss: 0.1112 - val_binary_accuracy: 0.9600\n",
      "Epoch 47/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0860 - binary_accuracy: 0.9685 - val_loss: 0.1120 - val_binary_accuracy: 0.9595\n",
      "Epoch 48/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0852 - binary_accuracy: 0.9685 - val_loss: 0.1125 - val_binary_accuracy: 0.9592\n",
      "Epoch 49/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0854 - binary_accuracy: 0.9682 - val_loss: 0.1127 - val_binary_accuracy: 0.9596\n",
      "Epoch 50/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0851 - binary_accuracy: 0.9682 - val_loss: 0.1120 - val_binary_accuracy: 0.9598\n",
      "Epoch 51/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0851 - binary_accuracy: 0.9682 - val_loss: 0.1127 - val_binary_accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0847 - binary_accuracy: 0.9686 - val_loss: 0.1118 - val_binary_accuracy: 0.9605\n",
      "Epoch 53/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0846 - binary_accuracy: 0.9687 - val_loss: 0.1119 - val_binary_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0848 - binary_accuracy: 0.9685 - val_loss: 0.1121 - val_binary_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0842 - binary_accuracy: 0.9688 - val_loss: 0.1125 - val_binary_accuracy: 0.9595\n",
      "Epoch 56/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0842 - binary_accuracy: 0.9688 - val_loss: 0.1121 - val_binary_accuracy: 0.9602\n",
      "Epoch 57/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0845 - binary_accuracy: 0.9691 - val_loss: 0.1119 - val_binary_accuracy: 0.9604\n",
      "Epoch 58/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0835 - binary_accuracy: 0.9693 - val_loss: 0.1119 - val_binary_accuracy: 0.9603\n",
      "Epoch 59/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0833 - binary_accuracy: 0.9693 - val_loss: 0.1121 - val_binary_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0844 - binary_accuracy: 0.9689 - val_loss: 0.1122 - val_binary_accuracy: 0.9602\n",
      "Epoch 61/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0839 - binary_accuracy: 0.9688 - val_loss: 0.1119 - val_binary_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0843 - binary_accuracy: 0.9689 - val_loss: 0.1118 - val_binary_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.0835 - binary_accuracy: 0.9690 - val_loss: 0.1114 - val_binary_accuracy: 0.9605\n",
      "Epoch 64/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0837 - binary_accuracy: 0.9691 - val_loss: 0.1120 - val_binary_accuracy: 0.9599\n",
      "Epoch 65/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0835 - binary_accuracy: 0.9692 - val_loss: 0.1120 - val_binary_accuracy: 0.9603\n",
      "Epoch 66/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0840 - binary_accuracy: 0.9686 - val_loss: 0.1123 - val_binary_accuracy: 0.9602\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0840 - binary_accuracy: 0.9691 - val_loss: 0.1120 - val_binary_accuracy: 0.9600\n",
      "Epoch 68/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0834 - binary_accuracy: 0.9689 - val_loss: 0.1120 - val_binary_accuracy: 0.9603\n",
      "Epoch 69/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0840 - binary_accuracy: 0.9683 - val_loss: 0.1114 - val_binary_accuracy: 0.9605\n",
      "Epoch 70/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0830 - binary_accuracy: 0.9696 - val_loss: 0.1118 - val_binary_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "184800/184800 [==============================] - 86s 465us/step - loss: 0.0831 - binary_accuracy: 0.9691 - val_loss: 0.1116 - val_binary_accuracy: 0.9605\n",
      "Epoch 72/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0826 - binary_accuracy: 0.9694 - val_loss: 0.1120 - val_binary_accuracy: 0.9605\n",
      "Epoch 73/100\n",
      "184800/184800 [==============================] - 87s 472us/step - loss: 0.0829 - binary_accuracy: 0.9693 - val_loss: 0.1120 - val_binary_accuracy: 0.9603\n",
      "Epoch 74/100\n",
      "184800/184800 [==============================] - 87s 469us/step - loss: 0.0827 - binary_accuracy: 0.9695 - val_loss: 0.1120 - val_binary_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0838 - binary_accuracy: 0.9691 - val_loss: 0.1118 - val_binary_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "184800/184800 [==============================] - 87s 468us/step - loss: 0.0834 - binary_accuracy: 0.9696 - val_loss: 0.1119 - val_binary_accuracy: 0.9604\n",
      "Epoch 77/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0844 - binary_accuracy: 0.9684 - val_loss: 0.1119 - val_binary_accuracy: 0.9602\n",
      "Epoch 78/100\n",
      "184800/184800 [==============================] - 87s 471us/step - loss: 0.0827 - binary_accuracy: 0.9691 - val_loss: 0.1118 - val_binary_accuracy: 0.9602\n",
      "Epoch 79/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0832 - binary_accuracy: 0.9689 - val_loss: 0.1119 - val_binary_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0822 - binary_accuracy: 0.9698 - val_loss: 0.1120 - val_binary_accuracy: 0.9602\n",
      "Epoch 81/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0829 - binary_accuracy: 0.9697 - val_loss: 0.1118 - val_binary_accuracy: 0.9603\n",
      "Epoch 82/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0835 - binary_accuracy: 0.9688 - val_loss: 0.1118 - val_binary_accuracy: 0.9605\n",
      "Epoch 83/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0836 - binary_accuracy: 0.9691 - val_loss: 0.1117 - val_binary_accuracy: 0.9604\n",
      "Epoch 84/100\n",
      "184800/184800 [==============================] - 86s 463us/step - loss: 0.0820 - binary_accuracy: 0.9697 - val_loss: 0.1120 - val_binary_accuracy: 0.9601\n",
      "Epoch 85/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0826 - binary_accuracy: 0.9693 - val_loss: 0.1121 - val_binary_accuracy: 0.9601\n",
      "Epoch 86/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0827 - binary_accuracy: 0.9694 - val_loss: 0.1121 - val_binary_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "184800/184800 [==============================] - 86s 468us/step - loss: 0.0827 - binary_accuracy: 0.9694 - val_loss: 0.1118 - val_binary_accuracy: 0.9603\n",
      "Epoch 88/100\n",
      "184800/184800 [==============================] - 87s 470us/step - loss: 0.0835 - binary_accuracy: 0.9688 - val_loss: 0.1119 - val_binary_accuracy: 0.9603\n",
      "Epoch 89/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0833 - binary_accuracy: 0.9693 - val_loss: 0.1117 - val_binary_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "184800/184800 [==============================] - 86s 466us/step - loss: 0.0829 - binary_accuracy: 0.9693 - val_loss: 0.1118 - val_binary_accuracy: 0.9603\n",
      "Epoch 91/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0837 - binary_accuracy: 0.9693 - val_loss: 0.1119 - val_binary_accuracy: 0.9602\n",
      "Epoch 92/100\n",
      "184800/184800 [==============================] - 86s 467us/step - loss: 0.0828 - binary_accuracy: 0.9695 - val_loss: 0.1117 - val_binary_accuracy: 0.9601\n",
      "Epoch 93/100\n",
      "184800/184800 [==============================] - 86s 464us/step - loss: 0.0846 - binary_accuracy: 0.9688 - val_loss: 0.1117 - val_binary_accuracy: 0.9603\n",
      "184800/184800 [==============================] - 30s 161us/step\n",
      "(184800,)\n",
      "(184800,)\n",
      "61600/61600 [==============================] - 10s 162us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "61600/61600 [==============================] - 10s 161us/step\n",
      "(61600,)\n",
      "(61600,)\n",
      "                                     training_results\n",
      "0   sn : mean : 0.989647186147186 std : 0.00346226...\n",
      "1   sp : mean : 0.9776774891774892 std : 0.0053314...\n",
      "2   acc : mean : 0.9836623311042786 std : 0.004303...\n",
      "3   MCC : mean : 0.9673970245739569 std : 0.008584...\n",
      "4   AUC : mean : 0.9979295437796332 std : 0.000889...\n",
      "5   precision : mean : 0.9779526704965308 std : 0....\n",
      "6   F1 : mean : 0.9837635640524374 std : 0.0042620...\n",
      "7     lossValue : mean : 0.05064895 std : 0.011973396\n",
      "8                      ______________________________\n",
      "9                                  validation_results\n",
      "10  sn : mean : 0.9592792207792208 std : 0.0078609...\n",
      "11  sp : mean : 0.9257467532467534 std : 0.0302225...\n",
      "12  acc : mean : 0.9425129771232605 std : 0.017500...\n",
      "13  MCC : mean : 0.8858030330052596 std : 0.033957...\n",
      "14  AUC : mean : 0.981364530169506 std : 0.0099207...\n",
      "15  precision : mean : 0.9288228760863901 std : 0....\n",
      "16  F1 : mean : 0.9436533460193994 std : 0.0162690...\n",
      "17     lossValue : mean : 0.19516261 std : 0.08120857\n",
      "18                     ______________________________\n",
      "19                                    testing_results\n",
      "20  sn : mean : 0.9588636363636363 std : 0.0047234...\n",
      "21  sp : mean : 0.9270129870129871 std : 0.0170064...\n",
      "22  acc : mean : 0.9429383039474487 std : 0.008799...\n",
      "23  MCC : mean : 0.8864552665251033 std : 0.017085...\n",
      "24  AUC : mean : 0.9819697146441222 std : 0.005245...\n",
      "25  precision : mean : 0.9295143502785411 std : 0....\n",
      "26  F1 : mean : 0.9438927027352235 std : 0.0081916...\n",
      "27    lossValue : mean : 0.19126113 std : 0.044082906\n",
      "28                     ______________________________\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 31 10:17:08 2020\n",
    "\n",
    "@author: zeeshan\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 19 11:03:59 2020\n",
    "\n",
    "@author: zeeshan\n",
    "\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 11 16:27:11 2020\n",
    "\n",
    "@author: Zeeshan\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\";\n",
    "\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input,MaxPooling1D,Flatten,LeakyReLU,Activation,concatenate,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "#from group_norm import GroupNormalization\n",
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.metrics import binary_accuracy\n",
    "from sklearn.metrics import confusion_matrix,recall_score,matthews_corrcoef,roc_curve,roc_auc_score,auc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "import os, sys, copy, getopt, re, argparse\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "np.random.seed(seed=21)\n",
    "tf.__version__\n",
    "keras.__version__\n",
    "\n",
    "from keras import losses\n",
    "import pickle\n",
    "from scipy import interp\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "def analyze(temp, OutputDir):\n",
    "\n",
    "    # temp = None\n",
    "    # with open(dataFile, 'rb') as file:\n",
    "    #        temp = pickle.load(file)\n",
    "\n",
    "    trainning_result, validation_result, testing_result = temp;\n",
    "\n",
    "    file = open(OutputDir + '/performance.txt', 'w')\n",
    "\n",
    "    index = 0\n",
    "    for x in [trainning_result, validation_result, testing_result]:\n",
    "\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'training_'\n",
    "        if index == 1:\n",
    "            title = 'validation_'\n",
    "        if index == 2:\n",
    "            title = 'testing_'\n",
    "\n",
    "        index += 1;\n",
    "\n",
    "        file.write(title +  'results\\n')\n",
    "\n",
    "\n",
    "        for j in ['sn', 'sp', 'acc', 'MCC', 'AUC', 'precision', 'F1', 'lossValue']:\n",
    "\n",
    "            total = []\n",
    "\n",
    "            for val in x:\n",
    "                total.append(val[j])\n",
    "\n",
    "            file.write(j + ' : mean : ' + str(np.mean(total)) + ' std : ' + str(np.std(total))  + '\\n')\n",
    "\n",
    "        file.write('\\n\\n______________________________\\n')\n",
    "    file.close();\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for x in [trainning_result, validation_result, testing_result]:\n",
    "\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for val in x:\n",
    "            tpr = val['tpr']\n",
    "            fpr = val['fpr']\n",
    "            tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC fold %d (AUC = %0.2f)' % (i+1, roc_auc))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        print;\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'training_'\n",
    "        if index == 1:\n",
    "            title = 'validation_'\n",
    "        if index == 2:\n",
    "            title = 'testing_'\n",
    "\n",
    "        plt.savefig( OutputDir + '/' + title +'ROC.png')\n",
    "        plt.close('all');\n",
    "\n",
    "        index += 1;\n",
    "\n",
    "##############################   Scheduler ########################\n",
    "def scheduler(epochs, lr):\n",
    "  if epochs < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "####################################################################\n",
    "    \n",
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "    \n",
    "    return out\n",
    "\n",
    "def calculate(sequence):\n",
    "\n",
    "    X = []\n",
    "    dictNum = {'A' : 0, 'T' : 0, 'C' : 0, 'G' : 0};\n",
    "\n",
    "    for i in range(len(sequence)):\n",
    "\n",
    "        if sequence[i] in dictNum.keys():\n",
    "            dictNum[sequence[i]] += 1;\n",
    "            X.append(dictNum[sequence[i]] / float(i + 1));\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "def dataProcessing(path):\n",
    "\n",
    "    data = pd.read_csv(path);\n",
    "    alphabet = np.array(['A', 'G', 'T', 'C','0'])\n",
    "    X = [];\n",
    "    for line in data['data']:\n",
    "\n",
    "        line = list(line.strip('\\n'));\n",
    "        #scoreSequence = calculate2(line);\n",
    "        \n",
    "        seq = np.array(line, dtype = '|U1').reshape(-1,1);\n",
    "        seq_data = []\n",
    "\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == 'A':\n",
    "                seq_data.append([1,0,0,0])\n",
    "            if seq[i] == 'T':\n",
    "                seq_data.append([0,1,0,0])\n",
    "            if seq[i] == 'C':\n",
    "                seq_data.append([0,0,1,0])\n",
    "            if seq[i] == 'G':\n",
    "                seq_data.append([0,0,0,1])\n",
    "            if seq[i] == '0':\n",
    "                seq_data.append([0,0,0,0])\n",
    "                \n",
    "        X.append(np.array(seq_data));\n",
    "        \n",
    "    X = np.array(X);\n",
    "    y = np.array(data['label'], dtype = np.int32);\n",
    " \n",
    "    return X, y; #(n, 34, 4), (n,)\n",
    "\n",
    "def prepareData(PositiveCSV, NegativeCSV):\n",
    "\n",
    "    Positive_X, Positive_y = dataProcessing(PositiveCSV);\n",
    "    Negitive_X, Negitive_y = dataProcessing(NegativeCSV);\n",
    "\n",
    "    return Positive_X, Positive_y, Negitive_X, Negitive_y\n",
    "\n",
    "def shuffleData(X, y):\n",
    "    index = [i for i in range(len(X))]\n",
    "    random.shuffle(index)\n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    return X, y;\n",
    "\n",
    "#*******************Arch 3***********************#\n",
    "#************************************************#\n",
    "def spinal_cnn():\n",
    "    input_shape = (41,4)\n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    \n",
    "    conv0 = Conv1D(filters=16, kernel_size=5,strides=1)(inputs)\n",
    "    normLayer0 = BatchNormalization()(conv0);\n",
    "    #pool0 = MaxPooling1D(pool_size = 2)(normLayer0)\n",
    "    act0 = Activation(activation='relu')(normLayer0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv1 = Conv1D(filters=16, kernel_size=5,strides=1)(act0)\n",
    "    normLayer1 = BatchNormalization()(conv1);\n",
    "    pool1 = MaxPooling1D(pool_size = 2)(normLayer1)\n",
    "    act1 = Activation(activation='relu')(pool1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=32, kernel_size=5,strides=1)(act1)\n",
    "    normLayer2 = BatchNormalization()(conv2);\n",
    "    pool2 = MaxPooling1D(pool_size = 2)(normLayer2)\n",
    "    dropoutLayer1 = Dropout(0.25)(pool2)\n",
    "    act2 = Activation(activation='relu')(dropoutLayer1)\n",
    "    \n",
    "    x = Flatten()(act2)\n",
    "    \n",
    "    #x1 = keras.layers.Lambda(lambda x: x[:,0:112], output_shape=(112,))(x)\n",
    "    #x2 = keras.layers.Lambda(lambda x: x[:,112:], output_shape=(112,))(x)\n",
    "    \n",
    "    \n",
    "    #**************************************\n",
    "    \n",
    "    conv3 = Conv1D(filters=64, kernel_size=5,strides=1)(act0)\n",
    "    normLayer3 = BatchNormalization()(conv3);\n",
    "    pool3 = MaxPooling1D(pool_size = 2)(normLayer3)\n",
    "    act3 = Activation(activation='relu')(pool3)\n",
    "    \n",
    "    conv4 = Conv1D(filters=128, kernel_size=5,strides=1)(act3)\n",
    "    normLayer4 = BatchNormalization()(conv4);\n",
    "    pool4 = MaxPooling1D(pool_size = 2)(normLayer4)\n",
    "    dropoutLayer2 = Dropout(0.25)(pool4)\n",
    "    act4 = Activation(activation='relu')(dropoutLayer2)\n",
    "    \n",
    "    #conv3 = Conv1D(filters=64, kernel_size=5, strides=1)(pool2)\n",
    "    #pool3 = MaxPooling1D(pool_size = 2)(conv3)\n",
    "    #dropoutLayer = Dropout(0.25)(pool3) # Drop outtttttttt ############\n",
    "    #pool3 = Activation(activation='relu')(dropoutLayer)\n",
    "    \n",
    "    \n",
    "    a = Flatten()(act4)\n",
    "    comb = concatenate([x, a], axis=1)\n",
    "    \n",
    "    a1 = keras.layers.Lambda(lambda comb: comb[:,0:480], output_shape=(480,))(comb)\n",
    "    a2 = keras.layers.Lambda(lambda comb: comb[:,480:], output_shape=(480,))(comb)\n",
    "    \n",
    "    #x1 = x[:, 0:360]\n",
    "    \n",
    "    a1 = Dense(8, activation='relu')(a1) # Number of nodes in hidden layer\n",
    "    \n",
    "    a2 = concatenate([a2, a1])\n",
    "    a2 = Dense(8, activation='relu')(a2)\n",
    "    \n",
    "    a3 = concatenate([a1, a2])\n",
    "    a3 = Dense(8, activation='relu')(a3)\n",
    "    \n",
    "    a4 = concatenate([a2, a3])\n",
    "    a4 = Dense(8, activation='relu')(a4)\n",
    "    \n",
    "    a5 = concatenate([a1, a4])\n",
    "    a5 = Dense(8, activation='relu')(a3)\n",
    "    \n",
    "    a6 = concatenate([a2, a5])\n",
    "    a6 = Dense(8, activation='relu')(a6)\n",
    "    \n",
    "    a = concatenate([a1, a2], axis=1)\n",
    "    a = concatenate([a, a3], axis=1)\n",
    "    a = concatenate([a, a4], axis=1)\n",
    "    a = concatenate([a, a5], axis=1)\n",
    "    a = concatenate([a, a6], axis=1)\n",
    "    \n",
    "    #xa = concatenate([a, x], axis=1)\n",
    "    \n",
    "    \n",
    "    output = Dense(1, activation= 'sigmoid')(a)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    opt=SGD(learning_rate=0.001, momentum = 0.95)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= opt, metrics=[binary_accuracy]);\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def calculateScore(X, y, model, folds):\n",
    "    \n",
    "    score = model.evaluate(X,y)\n",
    "    pred_y = model.predict(X)\n",
    "\n",
    "    accuracy = score[1];\n",
    "\n",
    "    tempLabel = np.zeros(shape = y.shape, dtype=np.int32)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if pred_y[i] < 0.5:\n",
    "            tempLabel[i] = 0;\n",
    "        else:\n",
    "            tempLabel[i] = 1;\n",
    "    confusion = confusion_matrix(y, tempLabel)\n",
    "    TN, FP, FN, TP = confusion.ravel()\n",
    "\n",
    "    sensitivity = recall_score(y, tempLabel)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    MCC = matthews_corrcoef(y, tempLabel)\n",
    "\n",
    "    F1Score = (2 * TP) / float(2 * TP + FP + FN)\n",
    "    precision = TP / float(TP + FP)\n",
    "\n",
    "    pred_y = pred_y.reshape((-1, ))\n",
    "\n",
    "    ROCArea = roc_auc_score(y, pred_y)\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred_y)\n",
    "    lossValue = None;\n",
    "\n",
    "    print(y.shape)\n",
    "    print(pred_y.shape)\n",
    "\n",
    "    y_true = tf.convert_to_tensor(y, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(pred_y, np.float32)\n",
    "    \n",
    "    plt.show() #Extraaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
    "    #np.save('/home/zeeshan/SNNRice6mA-master/Output_test/chunk_folds/'+str(test_index)+'_'+'x_test',test_X)\n",
    "    #def figs(folds):\n",
    "    \n",
    "    #for fig in range(0, folds):\n",
    "      #plt.savefig('/home/zeeshan/SNNRice6mA-master/Output_test/fold_'+str(fig)+'.png')\n",
    "      \n",
    "        \n",
    "    #figs(folds)  # Extraaaaaaaaaaaaaaaa\n",
    "    #plt.savefig( OutputDir + '/' + title +'ROC.png')\n",
    "    \n",
    "    #with tf.compat.v1.Session():\n",
    "    #with tf.Session():\n",
    "    lossValue = losses.binary_crossentropy(y_true, y_pred)#.eval()\n",
    "\n",
    "    return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea, 'precision' : precision, 'F1' : F1Score, 'fpr' : fpr, 'tpr' : tpr, 'thresholds' : thresholds, 'lossValue' : lossValue}\n",
    "\n",
    "def funciton(PositiveCSV, NegativeCSV, OutputDir, folds):\n",
    "\n",
    "    Positive_X, Positive_y, Negitive_X, Negitive_y = prepareData(PositiveCSV, NegativeCSV)\n",
    "    \n",
    "    random.shuffle(Positive_X);\n",
    "    random.shuffle(Negitive_X);\n",
    "\n",
    "    Positive_X_Slices = chunkIt(Positive_X, folds);\n",
    "    Positive_y_Slices = chunkIt(Positive_y, folds);\n",
    "\n",
    "    Negative_X_Slices = chunkIt(Negitive_X, folds);\n",
    "    Negative_y_Slices = chunkIt(Negitive_y, folds);\n",
    "\n",
    "    trainning_result = []\n",
    "    validation_result = []\n",
    "    testing_result = []\n",
    "    \n",
    "    for test_index in range(folds):\n",
    "\n",
    "        test_X = np.concatenate((Positive_X_Slices[test_index],Negative_X_Slices[test_index]))\n",
    "        test_y = np.concatenate((Positive_y_Slices[test_index],Negative_y_Slices[test_index]))\n",
    "\n",
    "        validation_index = (test_index+1) % folds;\n",
    "\n",
    "        valid_X = np.concatenate((Positive_X_Slices[validation_index],Negative_X_Slices[validation_index]))\n",
    "        valid_y = np.concatenate((Positive_y_Slices[validation_index],Negative_y_Slices[validation_index]))\n",
    "\n",
    "        start = 0;\n",
    "\n",
    "        for val in range(0, folds):\n",
    "            if val != test_index and val != validation_index:\n",
    "                start = val;\n",
    "                break;\n",
    "\n",
    "        train_X = np.concatenate((Positive_X_Slices[start],Negative_X_Slices[start]))\n",
    "        train_y = np.concatenate((Positive_y_Slices[start],Negative_y_Slices[start]))\n",
    "\n",
    "        for i in range(0, folds):\n",
    "            if i != test_index and i != validation_index and i != start:\n",
    "                tempX = np.concatenate((Positive_X_Slices[i],Negative_X_Slices[i]))\n",
    "                tempy = np.concatenate((Positive_y_Slices[i],Negative_y_Slices[i]))\n",
    "\n",
    "                \n",
    "                train_X = np.concatenate((train_X, tempX))\n",
    "                train_y = np.concatenate((train_y, tempy))\n",
    "        print(np.shape(tempX),np.shape(train_X))\n",
    "        test_X, test_y = shuffleData(test_X,test_y);\n",
    "        valid_X,valid_y = shuffleData(valid_X,valid_y)\n",
    "        train_X,train_y = shuffleData(train_X,train_y);\n",
    "        \n",
    "        print(np.shape(train_X), np.shape(valid_X), np.shape(test_X))\n",
    "        \n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'x_test',test_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'y_test',test_y)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'valid_X',valid_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'valid_y',valid_y)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'x_train',train_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a/chunk_folds/'+str(test_index)+'_'+'y_train',train_y)\n",
    "        \n",
    "        \n",
    "        model = spinal_cnn();\n",
    "        #model = getMode();\n",
    "        \n",
    "        result_folder = OutputDir\n",
    "        if not os.path.exists(result_folder):\n",
    "            os.makedirs(result_folder)\n",
    "        model_results_folder=result_folder\n",
    "        \n",
    "        #best_weights = model_results_folder + 'best_weights.h5'\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_binary_accuracy', patience= 30, restore_best_weights=True)\n",
    "        model_check = ModelCheckpoint(filepath = OutputDir + \"/model\" + str(test_index+1) +\".h5\", monitor = 'val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "        #reduct_L_rate = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=20)\n",
    "        reduct_L_rate = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        \n",
    "        cbacks = [model_check, early_stopping,reduct_L_rate]\n",
    "        #cbacks = [model_check, early_stopping]\n",
    "        \n",
    "        #####################Call back #########################\n",
    "        #callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        ########################################################\n",
    "        \n",
    "        history = model.fit(train_X, train_y, batch_size = 32, epochs = 100, validation_data = (valid_X, valid_y),callbacks = cbacks);\n",
    "        \n",
    "        \n",
    "        trainning_result.append(calculateScore(train_X, train_y, model, folds));\n",
    "        validation_result.append(calculateScore(valid_X, valid_y, model, folds));\n",
    "        testing_result.append(calculateScore(test_X, test_y, model, folds));\n",
    "\n",
    "    temp_dict = (trainning_result, validation_result, testing_result)\n",
    "    analyze(temp_dict, OutputDir);\n",
    "    \n",
    "\n",
    "\n",
    "PositiveCSV = 'pos.txt'\n",
    "NegativeCSV = 'neg.txt'\n",
    "#PositiveCSV = 'Positive_Chen.txt'\n",
    "#NegativeCSV = 'Negative_Chen.txt'\n",
    "#OutputDir = 'D:/Zeeshan/Methylation/SNNRice6ma/SNNRice6mA-Zeeshan'\n",
    "OutputDir = '/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_again/'\n",
    "funciton(PositiveCSV, NegativeCSV, OutputDir, 5);\n",
    "\n",
    "result = pd.read_csv('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_again/performance.txt')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
