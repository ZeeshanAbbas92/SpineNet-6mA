{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 6s 5ms/step - loss: 0.7854 - binary_accuracy: 0.5149 - val_loss: 0.6826 - val_binary_accuracy: 0.6307\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.5985 - binary_accuracy: 0.6776 - val_loss: 0.6314 - val_binary_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.4466 - binary_accuracy: 0.7884 - val_loss: 0.5187 - val_binary_accuracy: 0.8920\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.3184 - binary_accuracy: 0.8636 - val_loss: 0.3898 - val_binary_accuracy: 0.9148\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.2561 - binary_accuracy: 0.9027 - val_loss: 0.2829 - val_binary_accuracy: 0.9261\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 375us/step - loss: 0.2090 - binary_accuracy: 0.9219 - val_loss: 0.2071 - val_binary_accuracy: 0.9489\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 1s 389us/step - loss: 0.1731 - binary_accuracy: 0.9339 - val_loss: 0.1660 - val_binary_accuracy: 0.9432\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 367us/step - loss: 0.1551 - binary_accuracy: 0.9382 - val_loss: 0.1445 - val_binary_accuracy: 0.9489\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.1372 - binary_accuracy: 0.9510 - val_loss: 0.1561 - val_binary_accuracy: 0.9318\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.1332 - binary_accuracy: 0.9517 - val_loss: 0.1200 - val_binary_accuracy: 0.9432\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 1s 373us/step - loss: 0.1112 - binary_accuracy: 0.9609 - val_loss: 0.0907 - val_binary_accuracy: 0.9943\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.1015 - binary_accuracy: 0.9624 - val_loss: 0.1256 - val_binary_accuracy: 0.9432\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 1s 377us/step - loss: 0.0944 - binary_accuracy: 0.9652 - val_loss: 0.0938 - val_binary_accuracy: 0.9602\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 1s 379us/step - loss: 0.0877 - binary_accuracy: 0.9652 - val_loss: 0.0890 - val_binary_accuracy: 0.9773\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 1s 386us/step - loss: 0.0674 - binary_accuracy: 0.9773 - val_loss: 0.0918 - val_binary_accuracy: 0.9773\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 385us/step - loss: 0.0620 - binary_accuracy: 0.9794 - val_loss: 0.0777 - val_binary_accuracy: 0.9773\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 1s 398us/step - loss: 0.0609 - binary_accuracy: 0.9744 - val_loss: 0.0947 - val_binary_accuracy: 0.9602\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 414us/step - loss: 0.0784 - binary_accuracy: 0.9702 - val_loss: 0.0783 - val_binary_accuracy: 0.9773\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.0450 - binary_accuracy: 0.9851 - val_loss: 0.0860 - val_binary_accuracy: 0.9602\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0424 - binary_accuracy: 0.9865 - val_loss: 0.0978 - val_binary_accuracy: 0.9602\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0473 - binary_accuracy: 0.9815 - val_loss: 0.0799 - val_binary_accuracy: 0.9773\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0426 - binary_accuracy: 0.9858 - val_loss: 0.0794 - val_binary_accuracy: 0.9773\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.0496 - binary_accuracy: 0.9808 - val_loss: 0.0756 - val_binary_accuracy: 0.9773\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0431 - binary_accuracy: 0.9858 - val_loss: 0.0663 - val_binary_accuracy: 0.9943\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0346 - binary_accuracy: 0.9879 - val_loss: 0.0743 - val_binary_accuracy: 0.9773\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0380 - binary_accuracy: 0.9886 - val_loss: 0.0792 - val_binary_accuracy: 0.9773\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0374 - binary_accuracy: 0.9872 - val_loss: 0.0705 - val_binary_accuracy: 0.9773\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0345 - binary_accuracy: 0.9872 - val_loss: 0.0773 - val_binary_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.0329 - binary_accuracy: 0.9901 - val_loss: 0.0740 - val_binary_accuracy: 0.9773\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0429 - binary_accuracy: 0.9858 - val_loss: 0.0713 - val_binary_accuracy: 0.9773\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0336 - binary_accuracy: 0.9901 - val_loss: 0.0745 - val_binary_accuracy: 0.9773\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 1s 393us/step - loss: 0.0363 - binary_accuracy: 0.9886 - val_loss: 0.0737 - val_binary_accuracy: 0.9773\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 1s 387us/step - loss: 0.0368 - binary_accuracy: 0.9872 - val_loss: 0.0773 - val_binary_accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0352 - binary_accuracy: 0.9908 - val_loss: 0.0777 - val_binary_accuracy: 0.9773\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0330 - binary_accuracy: 0.9886 - val_loss: 0.0798 - val_binary_accuracy: 0.9773\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0297 - binary_accuracy: 0.9915 - val_loss: 0.0753 - val_binary_accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0252 - binary_accuracy: 0.9922 - val_loss: 0.0728 - val_binary_accuracy: 0.9773\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0312 - binary_accuracy: 0.9908 - val_loss: 0.0738 - val_binary_accuracy: 0.9773\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0306 - binary_accuracy: 0.9915 - val_loss: 0.0775 - val_binary_accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0299 - binary_accuracy: 0.9893 - val_loss: 0.0741 - val_binary_accuracy: 0.9773\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0306 - binary_accuracy: 0.9915 - val_loss: 0.0747 - val_binary_accuracy: 0.9773\n",
      "1408/1408 [==============================] - 0s 131us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 144us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 137us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 1ms/step - loss: 0.7066 - binary_accuracy: 0.5206 - val_loss: 0.6899 - val_binary_accuracy: 0.5114\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.6540 - binary_accuracy: 0.5966 - val_loss: 0.6627 - val_binary_accuracy: 0.7784\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.5079 - binary_accuracy: 0.7386 - val_loss: 0.5288 - val_binary_accuracy: 0.8807\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.3611 - binary_accuracy: 0.8409 - val_loss: 0.3985 - val_binary_accuracy: 0.9091\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.2579 - binary_accuracy: 0.8991 - val_loss: 0.2737 - val_binary_accuracy: 0.9318\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.2320 - binary_accuracy: 0.9112 - val_loss: 0.1815 - val_binary_accuracy: 0.9602\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.1874 - binary_accuracy: 0.9233 - val_loss: 0.1370 - val_binary_accuracy: 0.9659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 368us/step - loss: 0.1577 - binary_accuracy: 0.9418 - val_loss: 0.1013 - val_binary_accuracy: 0.9830\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.1384 - binary_accuracy: 0.9503 - val_loss: 0.0918 - val_binary_accuracy: 0.9773\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.1257 - binary_accuracy: 0.9517 - val_loss: 0.0665 - val_binary_accuracy: 0.9886\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.1127 - binary_accuracy: 0.9531 - val_loss: 0.0898 - val_binary_accuracy: 0.9545\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 1s 401us/step - loss: 0.0980 - binary_accuracy: 0.9673 - val_loss: 0.0611 - val_binary_accuracy: 0.9716\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 1s 400us/step - loss: 0.0889 - binary_accuracy: 0.9666 - val_loss: 0.0553 - val_binary_accuracy: 0.9830\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0783 - binary_accuracy: 0.9695 - val_loss: 0.0565 - val_binary_accuracy: 0.9773\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0702 - binary_accuracy: 0.9766 - val_loss: 0.0587 - val_binary_accuracy: 0.9773\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 386us/step - loss: 0.0708 - binary_accuracy: 0.9737 - val_loss: 0.0458 - val_binary_accuracy: 0.9886\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 1s 386us/step - loss: 0.0633 - binary_accuracy: 0.9794 - val_loss: 0.0513 - val_binary_accuracy: 0.9773\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 379us/step - loss: 0.0697 - binary_accuracy: 0.9766 - val_loss: 0.0483 - val_binary_accuracy: 0.9830\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 1s 381us/step - loss: 0.0508 - binary_accuracy: 0.9822 - val_loss: 0.0553 - val_binary_accuracy: 0.9773\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0414 - binary_accuracy: 0.9872 - val_loss: 0.0585 - val_binary_accuracy: 0.9773\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0482 - binary_accuracy: 0.9851 - val_loss: 0.0685 - val_binary_accuracy: 0.9773\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0586 - binary_accuracy: 0.9759 - val_loss: 0.0529 - val_binary_accuracy: 0.9830\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0468 - binary_accuracy: 0.9851 - val_loss: 0.0660 - val_binary_accuracy: 0.9716\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0474 - binary_accuracy: 0.9851 - val_loss: 0.0799 - val_binary_accuracy: 0.9716\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0480 - binary_accuracy: 0.9865 - val_loss: 0.0609 - val_binary_accuracy: 0.9830\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0494 - binary_accuracy: 0.9837 - val_loss: 0.0530 - val_binary_accuracy: 0.9830\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0460 - binary_accuracy: 0.9830 - val_loss: 0.0640 - val_binary_accuracy: 0.9773\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0453 - binary_accuracy: 0.9837 - val_loss: 0.0670 - val_binary_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0356 - binary_accuracy: 0.9858 - val_loss: 0.0567 - val_binary_accuracy: 0.9830\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.0421 - binary_accuracy: 0.9837 - val_loss: 0.0607 - val_binary_accuracy: 0.9773\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.0393 - binary_accuracy: 0.9851 - val_loss: 0.0646 - val_binary_accuracy: 0.9716\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0338 - binary_accuracy: 0.9893 - val_loss: 0.0622 - val_binary_accuracy: 0.9716\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0451 - binary_accuracy: 0.9815 - val_loss: 0.0610 - val_binary_accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.0475 - binary_accuracy: 0.9822 - val_loss: 0.0641 - val_binary_accuracy: 0.9773\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0444 - binary_accuracy: 0.9837 - val_loss: 0.0637 - val_binary_accuracy: 0.9773\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0385 - binary_accuracy: 0.9865 - val_loss: 0.0575 - val_binary_accuracy: 0.9830\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0356 - binary_accuracy: 0.9851 - val_loss: 0.0635 - val_binary_accuracy: 0.9773\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0316 - binary_accuracy: 0.9901 - val_loss: 0.0620 - val_binary_accuracy: 0.9773\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0425 - binary_accuracy: 0.9844 - val_loss: 0.0581 - val_binary_accuracy: 0.9830\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 1s 381us/step - loss: 0.0322 - binary_accuracy: 0.9893 - val_loss: 0.0655 - val_binary_accuracy: 0.9773\n",
      "1408/1408 [==============================] - 0s 130us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 139us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 138us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 913us/step - loss: 0.7090 - binary_accuracy: 0.5717 - val_loss: 0.6832 - val_binary_accuracy: 0.6648\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.5315 - binary_accuracy: 0.7322 - val_loss: 0.6255 - val_binary_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.3678 - binary_accuracy: 0.8338 - val_loss: 0.5173 - val_binary_accuracy: 0.8523\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.2587 - binary_accuracy: 0.8949 - val_loss: 0.4069 - val_binary_accuracy: 0.8352\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.2035 - binary_accuracy: 0.9219 - val_loss: 0.3092 - val_binary_accuracy: 0.8920\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 360us/step - loss: 0.1728 - binary_accuracy: 0.9318 - val_loss: 0.2213 - val_binary_accuracy: 0.9375\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.1547 - binary_accuracy: 0.9482 - val_loss: 0.1728 - val_binary_accuracy: 0.9489\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 368us/step - loss: 0.1222 - binary_accuracy: 0.9574 - val_loss: 0.1560 - val_binary_accuracy: 0.9261\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 392us/step - loss: 0.1239 - binary_accuracy: 0.9510 - val_loss: 0.1368 - val_binary_accuracy: 0.9261\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0970 - binary_accuracy: 0.9652 - val_loss: 0.1258 - val_binary_accuracy: 0.9432\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 0s 340us/step - loss: 0.0807 - binary_accuracy: 0.9737 - val_loss: 0.1037 - val_binary_accuracy: 0.9659\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0725 - binary_accuracy: 0.9744 - val_loss: 0.0925 - val_binary_accuracy: 0.9602\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.0620 - binary_accuracy: 0.9773 - val_loss: 0.0907 - val_binary_accuracy: 0.9659\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0592 - binary_accuracy: 0.9773 - val_loss: 0.0899 - val_binary_accuracy: 0.9602\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.0570 - binary_accuracy: 0.9787 - val_loss: 0.0845 - val_binary_accuracy: 0.9602\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.0550 - binary_accuracy: 0.9780 - val_loss: 0.0830 - val_binary_accuracy: 0.9659\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.0506 - binary_accuracy: 0.9830 - val_loss: 0.0948 - val_binary_accuracy: 0.9602\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0378 - binary_accuracy: 0.9893 - val_loss: 0.0965 - val_binary_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.0564 - binary_accuracy: 0.9780 - val_loss: 0.1043 - val_binary_accuracy: 0.9602\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.0384 - binary_accuracy: 0.9858 - val_loss: 0.1066 - val_binary_accuracy: 0.9602\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0371 - binary_accuracy: 0.9879 - val_loss: 0.0901 - val_binary_accuracy: 0.9602\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0334 - binary_accuracy: 0.9922 - val_loss: 0.0905 - val_binary_accuracy: 0.9602\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 1s 369us/step - loss: 0.0359 - binary_accuracy: 0.9872 - val_loss: 0.0936 - val_binary_accuracy: 0.9602\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 406us/step - loss: 0.0370 - binary_accuracy: 0.9879 - val_loss: 0.0979 - val_binary_accuracy: 0.9602\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 1s 371us/step - loss: 0.0390 - binary_accuracy: 0.9851 - val_loss: 0.0877 - val_binary_accuracy: 0.9602\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0333 - binary_accuracy: 0.9908 - val_loss: 0.0875 - val_binary_accuracy: 0.9602\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0288 - binary_accuracy: 0.9908 - val_loss: 0.0819 - val_binary_accuracy: 0.9602\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 374us/step - loss: 0.0275 - binary_accuracy: 0.9908 - val_loss: 0.0810 - val_binary_accuracy: 0.9602\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 381us/step - loss: 0.0298 - binary_accuracy: 0.9908 - val_loss: 0.0813 - val_binary_accuracy: 0.9602\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.0466 - binary_accuracy: 0.9808 - val_loss: 0.0816 - val_binary_accuracy: 0.9602\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0323 - binary_accuracy: 0.9893 - val_loss: 0.0796 - val_binary_accuracy: 0.9659\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0273 - binary_accuracy: 0.9915 - val_loss: 0.0811 - val_binary_accuracy: 0.9602\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0317 - binary_accuracy: 0.9908 - val_loss: 0.0807 - val_binary_accuracy: 0.9602\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0298 - binary_accuracy: 0.9901 - val_loss: 0.0833 - val_binary_accuracy: 0.9602\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 1s 386us/step - loss: 0.0309 - binary_accuracy: 0.9893 - val_loss: 0.0840 - val_binary_accuracy: 0.9602\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0271 - binary_accuracy: 0.9929 - val_loss: 0.0823 - val_binary_accuracy: 0.9659\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.0344 - binary_accuracy: 0.9872 - val_loss: 0.0829 - val_binary_accuracy: 0.9659\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.0252 - binary_accuracy: 0.9929 - val_loss: 0.0841 - val_binary_accuracy: 0.9659\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0231 - binary_accuracy: 0.9929 - val_loss: 0.0852 - val_binary_accuracy: 0.9602\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.0344 - binary_accuracy: 0.9865 - val_loss: 0.0836 - val_binary_accuracy: 0.9659\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.0329 - binary_accuracy: 0.9879 - val_loss: 0.0842 - val_binary_accuracy: 0.9602\n",
      "1408/1408 [==============================] - 0s 128us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 139us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 140us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 926us/step - loss: 0.7659 - binary_accuracy: 0.5000 - val_loss: 0.6921 - val_binary_accuracy: 0.4943\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.6814 - binary_accuracy: 0.5661 - val_loss: 0.6878 - val_binary_accuracy: 0.5511\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.6227 - binary_accuracy: 0.6619 - val_loss: 0.6581 - val_binary_accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.5101 - binary_accuracy: 0.7599 - val_loss: 0.5652 - val_binary_accuracy: 0.7784\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.3847 - binary_accuracy: 0.8295 - val_loss: 0.4588 - val_binary_accuracy: 0.8352\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.2996 - binary_accuracy: 0.8786 - val_loss: 0.3620 - val_binary_accuracy: 0.8750\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.2386 - binary_accuracy: 0.9077 - val_loss: 0.3067 - val_binary_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.1900 - binary_accuracy: 0.9290 - val_loss: 0.2668 - val_binary_accuracy: 0.8977\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.1645 - binary_accuracy: 0.9411 - val_loss: 0.2415 - val_binary_accuracy: 0.9034\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.1464 - binary_accuracy: 0.9368 - val_loss: 0.2331 - val_binary_accuracy: 0.8977\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.1288 - binary_accuracy: 0.9553 - val_loss: 0.2783 - val_binary_accuracy: 0.8977\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.1111 - binary_accuracy: 0.9574 - val_loss: 0.2576 - val_binary_accuracy: 0.9091\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 0s 340us/step - loss: 0.0873 - binary_accuracy: 0.9723 - val_loss: 0.2331 - val_binary_accuracy: 0.9091\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.0850 - binary_accuracy: 0.9702 - val_loss: 0.2214 - val_binary_accuracy: 0.9205\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0733 - binary_accuracy: 0.9730 - val_loss: 0.2276 - val_binary_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 377us/step - loss: 0.0769 - binary_accuracy: 0.9716 - val_loss: 0.2265 - val_binary_accuracy: 0.9205\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0533 - binary_accuracy: 0.9815 - val_loss: 0.2351 - val_binary_accuracy: 0.9205\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.0606 - binary_accuracy: 0.9780 - val_loss: 0.2680 - val_binary_accuracy: 0.9148\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 1s 372us/step - loss: 0.0613 - binary_accuracy: 0.9766 - val_loss: 0.2480 - val_binary_accuracy: 0.9148\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 374us/step - loss: 0.0448 - binary_accuracy: 0.9872 - val_loss: 0.2435 - val_binary_accuracy: 0.9091\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 374us/step - loss: 0.0496 - binary_accuracy: 0.9858 - val_loss: 0.2333 - val_binary_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0472 - binary_accuracy: 0.9865 - val_loss: 0.2631 - val_binary_accuracy: 0.9205\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 0s 320us/step - loss: 0.0462 - binary_accuracy: 0.9844 - val_loss: 0.2494 - val_binary_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0442 - binary_accuracy: 0.9837 - val_loss: 0.2654 - val_binary_accuracy: 0.9148\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 0s 317us/step - loss: 0.0403 - binary_accuracy: 0.9872 - val_loss: 0.2510 - val_binary_accuracy: 0.8977\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 323us/step - loss: 0.0420 - binary_accuracy: 0.9865 - val_loss: 0.2491 - val_binary_accuracy: 0.9034\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0337 - binary_accuracy: 0.9915 - val_loss: 0.2529 - val_binary_accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0462 - binary_accuracy: 0.9844 - val_loss: 0.2486 - val_binary_accuracy: 0.9091\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 0s 328us/step - loss: 0.0353 - binary_accuracy: 0.9908 - val_loss: 0.2468 - val_binary_accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 0s 335us/step - loss: 0.0351 - binary_accuracy: 0.9908 - val_loss: 0.2522 - val_binary_accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 1s 368us/step - loss: 0.0506 - binary_accuracy: 0.9801 - val_loss: 0.2438 - val_binary_accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0351 - binary_accuracy: 0.9879 - val_loss: 0.2464 - val_binary_accuracy: 0.9091\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0377 - binary_accuracy: 0.9865 - val_loss: 0.2585 - val_binary_accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0312 - binary_accuracy: 0.9915 - val_loss: 0.2532 - val_binary_accuracy: 0.9091\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0298 - binary_accuracy: 0.9901 - val_loss: 0.2533 - val_binary_accuracy: 0.9091\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0395 - binary_accuracy: 0.9865 - val_loss: 0.2565 - val_binary_accuracy: 0.9091\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 331us/step - loss: 0.0333 - binary_accuracy: 0.9886 - val_loss: 0.2482 - val_binary_accuracy: 0.9034\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0396 - binary_accuracy: 0.9872 - val_loss: 0.2487 - val_binary_accuracy: 0.9034\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0402 - binary_accuracy: 0.9837 - val_loss: 0.2579 - val_binary_accuracy: 0.9091\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0401 - binary_accuracy: 0.9851 - val_loss: 0.2570 - val_binary_accuracy: 0.9091\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0306 - binary_accuracy: 0.9908 - val_loss: 0.2524 - val_binary_accuracy: 0.9091\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0353 - binary_accuracy: 0.9879 - val_loss: 0.2586 - val_binary_accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0377 - binary_accuracy: 0.9844 - val_loss: 0.2595 - val_binary_accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0337 - binary_accuracy: 0.9908 - val_loss: 0.2543 - val_binary_accuracy: 0.9091\n",
      "Epoch 45/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0360 - binary_accuracy: 0.9858 - val_loss: 0.2529 - val_binary_accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0356 - binary_accuracy: 0.9893 - val_loss: 0.2550 - val_binary_accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0450 - binary_accuracy: 0.9787 - val_loss: 0.2528 - val_binary_accuracy: 0.9091\n",
      "Epoch 48/100\n",
      "1408/1408 [==============================] - 0s 333us/step - loss: 0.0382 - binary_accuracy: 0.9851 - val_loss: 0.2513 - val_binary_accuracy: 0.9034\n",
      "Epoch 49/100\n",
      "1408/1408 [==============================] - 0s 334us/step - loss: 0.0318 - binary_accuracy: 0.9872 - val_loss: 0.2525 - val_binary_accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "1408/1408 [==============================] - 0s 333us/step - loss: 0.0398 - binary_accuracy: 0.9865 - val_loss: 0.2510 - val_binary_accuracy: 0.9034\n",
      "Epoch 51/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0350 - binary_accuracy: 0.9851 - val_loss: 0.2510 - val_binary_accuracy: 0.9034\n",
      "1408/1408 [==============================] - 0s 130us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 136us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 129us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 921us/step - loss: 0.7353 - binary_accuracy: 0.5426 - val_loss: 0.6885 - val_binary_accuracy: 0.6420\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.5751 - binary_accuracy: 0.6967 - val_loss: 0.6380 - val_binary_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.4035 - binary_accuracy: 0.8139 - val_loss: 0.5241 - val_binary_accuracy: 0.8636\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 1s 388us/step - loss: 0.2608 - binary_accuracy: 0.8906 - val_loss: 0.3990 - val_binary_accuracy: 0.9205\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.2222 - binary_accuracy: 0.9062 - val_loss: 0.2984 - val_binary_accuracy: 0.9489\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.1723 - binary_accuracy: 0.9368 - val_loss: 0.2280 - val_binary_accuracy: 0.9432\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.1311 - binary_accuracy: 0.9517 - val_loss: 0.2218 - val_binary_accuracy: 0.9261\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.1217 - binary_accuracy: 0.9581 - val_loss: 0.1606 - val_binary_accuracy: 0.9602\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.1155 - binary_accuracy: 0.9581 - val_loss: 0.1580 - val_binary_accuracy: 0.9489\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.1020 - binary_accuracy: 0.9602 - val_loss: 0.1568 - val_binary_accuracy: 0.9489\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0855 - binary_accuracy: 0.9709 - val_loss: 0.1516 - val_binary_accuracy: 0.9602\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0909 - binary_accuracy: 0.9652 - val_loss: 0.1456 - val_binary_accuracy: 0.9489\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0616 - binary_accuracy: 0.9794 - val_loss: 0.1403 - val_binary_accuracy: 0.9489\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0639 - binary_accuracy: 0.9787 - val_loss: 0.1513 - val_binary_accuracy: 0.9489\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0581 - binary_accuracy: 0.9787 - val_loss: 0.1379 - val_binary_accuracy: 0.9545\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 377us/step - loss: 0.0452 - binary_accuracy: 0.9844 - val_loss: 0.1353 - val_binary_accuracy: 0.9602\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0441 - binary_accuracy: 0.9858 - val_loss: 0.1335 - val_binary_accuracy: 0.9545\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0406 - binary_accuracy: 0.9886 - val_loss: 0.1381 - val_binary_accuracy: 0.9659\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.0415 - binary_accuracy: 0.9872 - val_loss: 0.1361 - val_binary_accuracy: 0.9659\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 0s 330us/step - loss: 0.0600 - binary_accuracy: 0.9808 - val_loss: 0.1414 - val_binary_accuracy: 0.9545\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1408 [==============================] - 0s 329us/step - loss: 0.0422 - binary_accuracy: 0.9815 - val_loss: 0.1502 - val_binary_accuracy: 0.9489\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.0426 - binary_accuracy: 0.9858 - val_loss: 0.1414 - val_binary_accuracy: 0.9659\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 1s 371us/step - loss: 0.0371 - binary_accuracy: 0.9858 - val_loss: 0.1406 - val_binary_accuracy: 0.9489\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0414 - binary_accuracy: 0.9844 - val_loss: 0.1389 - val_binary_accuracy: 0.9659\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.0335 - binary_accuracy: 0.9893 - val_loss: 0.1380 - val_binary_accuracy: 0.9659\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0373 - binary_accuracy: 0.9865 - val_loss: 0.1368 - val_binary_accuracy: 0.9659\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0304 - binary_accuracy: 0.9893 - val_loss: 0.1382 - val_binary_accuracy: 0.9659\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 369us/step - loss: 0.0255 - binary_accuracy: 0.9929 - val_loss: 0.1404 - val_binary_accuracy: 0.9659\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 393us/step - loss: 0.0382 - binary_accuracy: 0.9844 - val_loss: 0.1420 - val_binary_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 407us/step - loss: 0.0353 - binary_accuracy: 0.9879 - val_loss: 0.1415 - val_binary_accuracy: 0.9659\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.0271 - binary_accuracy: 0.9901 - val_loss: 0.1409 - val_binary_accuracy: 0.9659\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0307 - binary_accuracy: 0.9893 - val_loss: 0.1396 - val_binary_accuracy: 0.9659\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0210 - binary_accuracy: 0.9957 - val_loss: 0.1393 - val_binary_accuracy: 0.9659\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0271 - binary_accuracy: 0.9879 - val_loss: 0.1385 - val_binary_accuracy: 0.9659\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0287 - binary_accuracy: 0.9901 - val_loss: 0.1376 - val_binary_accuracy: 0.9659\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.0253 - binary_accuracy: 0.9922 - val_loss: 0.1376 - val_binary_accuracy: 0.9659\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0229 - binary_accuracy: 0.9929 - val_loss: 0.1372 - val_binary_accuracy: 0.9659\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0283 - binary_accuracy: 0.9915 - val_loss: 0.1377 - val_binary_accuracy: 0.9659\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.0251 - binary_accuracy: 0.9908 - val_loss: 0.1380 - val_binary_accuracy: 0.9659\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 1s 367us/step - loss: 0.0321 - binary_accuracy: 0.9872 - val_loss: 0.1374 - val_binary_accuracy: 0.9659\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0292 - binary_accuracy: 0.9901 - val_loss: 0.1382 - val_binary_accuracy: 0.9659\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0298 - binary_accuracy: 0.9893 - val_loss: 0.1382 - val_binary_accuracy: 0.9659\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0243 - binary_accuracy: 0.9929 - val_loss: 0.1387 - val_binary_accuracy: 0.9659\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0266 - binary_accuracy: 0.9929 - val_loss: 0.1388 - val_binary_accuracy: 0.9659\n",
      "Epoch 45/100\n",
      "1408/1408 [==============================] - 1s 371us/step - loss: 0.0216 - binary_accuracy: 0.9929 - val_loss: 0.1383 - val_binary_accuracy: 0.9659\n",
      "Epoch 46/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0277 - binary_accuracy: 0.9908 - val_loss: 0.1381 - val_binary_accuracy: 0.9659\n",
      "Epoch 47/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0240 - binary_accuracy: 0.9915 - val_loss: 0.1381 - val_binary_accuracy: 0.9659\n",
      "Epoch 48/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0213 - binary_accuracy: 0.9908 - val_loss: 0.1383 - val_binary_accuracy: 0.9659\n",
      "1408/1408 [==============================] - 0s 136us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 140us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 138us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 889us/step - loss: 0.7291 - binary_accuracy: 0.5043 - val_loss: 0.6927 - val_binary_accuracy: 0.5398\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.6293 - binary_accuracy: 0.6477 - val_loss: 0.6653 - val_binary_accuracy: 0.7670\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.4654 - binary_accuracy: 0.8018 - val_loss: 0.5586 - val_binary_accuracy: 0.8750\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.3382 - binary_accuracy: 0.8551 - val_loss: 0.4433 - val_binary_accuracy: 0.8864\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 337us/step - loss: 0.2540 - binary_accuracy: 0.9062 - val_loss: 0.3549 - val_binary_accuracy: 0.8920\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.2246 - binary_accuracy: 0.9077 - val_loss: 0.2866 - val_binary_accuracy: 0.8977\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.1704 - binary_accuracy: 0.9339 - val_loss: 0.2483 - val_binary_accuracy: 0.9091\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.1382 - binary_accuracy: 0.9489 - val_loss: 0.2144 - val_binary_accuracy: 0.9034\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 369us/step - loss: 0.1375 - binary_accuracy: 0.9510 - val_loss: 0.2061 - val_binary_accuracy: 0.9205\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.1188 - binary_accuracy: 0.9517 - val_loss: 0.1897 - val_binary_accuracy: 0.9091\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.1012 - binary_accuracy: 0.9631 - val_loss: 0.1826 - val_binary_accuracy: 0.9318\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0868 - binary_accuracy: 0.9737 - val_loss: 0.1817 - val_binary_accuracy: 0.9091\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0775 - binary_accuracy: 0.9787 - val_loss: 0.1805 - val_binary_accuracy: 0.9261\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0684 - binary_accuracy: 0.9759 - val_loss: 0.1708 - val_binary_accuracy: 0.9545\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0694 - binary_accuracy: 0.9730 - val_loss: 0.1736 - val_binary_accuracy: 0.9261\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 371us/step - loss: 0.0665 - binary_accuracy: 0.9773 - val_loss: 0.1765 - val_binary_accuracy: 0.9205\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0547 - binary_accuracy: 0.9808 - val_loss: 0.1627 - val_binary_accuracy: 0.9205\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0536 - binary_accuracy: 0.9773 - val_loss: 0.1816 - val_binary_accuracy: 0.9261\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 1s 403us/step - loss: 0.0417 - binary_accuracy: 0.9893 - val_loss: 0.1881 - val_binary_accuracy: 0.9261\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 385us/step - loss: 0.0452 - binary_accuracy: 0.9844 - val_loss: 0.1884 - val_binary_accuracy: 0.9205\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0483 - binary_accuracy: 0.9844 - val_loss: 0.1846 - val_binary_accuracy: 0.9261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0527 - binary_accuracy: 0.9766 - val_loss: 0.1818 - val_binary_accuracy: 0.9205\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 1s 393us/step - loss: 0.0414 - binary_accuracy: 0.9858 - val_loss: 0.1909 - val_binary_accuracy: 0.9261\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0420 - binary_accuracy: 0.9844 - val_loss: 0.1947 - val_binary_accuracy: 0.9148\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 1s 368us/step - loss: 0.0434 - binary_accuracy: 0.9872 - val_loss: 0.1890 - val_binary_accuracy: 0.9261\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.0392 - binary_accuracy: 0.9893 - val_loss: 0.1942 - val_binary_accuracy: 0.9205\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 1s 409us/step - loss: 0.0388 - binary_accuracy: 0.9879 - val_loss: 0.1947 - val_binary_accuracy: 0.9205\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 381us/step - loss: 0.0415 - binary_accuracy: 0.9886 - val_loss: 0.1922 - val_binary_accuracy: 0.9261\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0319 - binary_accuracy: 0.9915 - val_loss: 0.1903 - val_binary_accuracy: 0.9261\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0286 - binary_accuracy: 0.9922 - val_loss: 0.1870 - val_binary_accuracy: 0.9261\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 1s 373us/step - loss: 0.0321 - binary_accuracy: 0.9929 - val_loss: 0.1895 - val_binary_accuracy: 0.9261\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 1s 384us/step - loss: 0.0324 - binary_accuracy: 0.9908 - val_loss: 0.1891 - val_binary_accuracy: 0.9261\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0446 - binary_accuracy: 0.9844 - val_loss: 0.1934 - val_binary_accuracy: 0.9261\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.0273 - binary_accuracy: 0.9929 - val_loss: 0.1886 - val_binary_accuracy: 0.9261\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0363 - binary_accuracy: 0.9851 - val_loss: 0.1889 - val_binary_accuracy: 0.9261\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.0274 - binary_accuracy: 0.9922 - val_loss: 0.1901 - val_binary_accuracy: 0.9261\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 1s 360us/step - loss: 0.0283 - binary_accuracy: 0.9908 - val_loss: 0.1927 - val_binary_accuracy: 0.9261\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0273 - binary_accuracy: 0.9915 - val_loss: 0.1926 - val_binary_accuracy: 0.9261\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 1s 365us/step - loss: 0.0390 - binary_accuracy: 0.9879 - val_loss: 0.1915 - val_binary_accuracy: 0.9261\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 1s 394us/step - loss: 0.0301 - binary_accuracy: 0.9908 - val_loss: 0.1904 - val_binary_accuracy: 0.9261\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0281 - binary_accuracy: 0.9915 - val_loss: 0.1906 - val_binary_accuracy: 0.9261\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.0272 - binary_accuracy: 0.9936 - val_loss: 0.1916 - val_binary_accuracy: 0.9261\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.0328 - binary_accuracy: 0.9901 - val_loss: 0.1928 - val_binary_accuracy: 0.9261\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 1s 372us/step - loss: 0.0252 - binary_accuracy: 0.9936 - val_loss: 0.1944 - val_binary_accuracy: 0.9205\n",
      "1408/1408 [==============================] - 0s 128us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 119us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 128us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 913us/step - loss: 0.7254 - binary_accuracy: 0.5682 - val_loss: 0.6850 - val_binary_accuracy: 0.6080\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.5148 - binary_accuracy: 0.7763 - val_loss: 0.6228 - val_binary_accuracy: 0.7557\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 367us/step - loss: 0.3524 - binary_accuracy: 0.8445 - val_loss: 0.5267 - val_binary_accuracy: 0.8239\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.2683 - binary_accuracy: 0.8920 - val_loss: 0.4511 - val_binary_accuracy: 0.8636\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 1s 396us/step - loss: 0.2208 - binary_accuracy: 0.9098 - val_loss: 0.3935 - val_binary_accuracy: 0.8352\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.1662 - binary_accuracy: 0.9382 - val_loss: 0.3440 - val_binary_accuracy: 0.8693\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.1599 - binary_accuracy: 0.9432 - val_loss: 0.3034 - val_binary_accuracy: 0.8977\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 377us/step - loss: 0.1167 - binary_accuracy: 0.9616 - val_loss: 0.3133 - val_binary_accuracy: 0.8864\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 397us/step - loss: 0.0999 - binary_accuracy: 0.9581 - val_loss: 0.3144 - val_binary_accuracy: 0.8920\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0926 - binary_accuracy: 0.9723 - val_loss: 0.3036 - val_binary_accuracy: 0.8977\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0881 - binary_accuracy: 0.9695 - val_loss: 0.3250 - val_binary_accuracy: 0.9034\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 1s 374us/step - loss: 0.0634 - binary_accuracy: 0.9815 - val_loss: 0.3539 - val_binary_accuracy: 0.9034\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 1s 378us/step - loss: 0.0637 - binary_accuracy: 0.9808 - val_loss: 0.3455 - val_binary_accuracy: 0.9091\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0529 - binary_accuracy: 0.9815 - val_loss: 0.3675 - val_binary_accuracy: 0.9091\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0533 - binary_accuracy: 0.9822 - val_loss: 0.3562 - val_binary_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 387us/step - loss: 0.0605 - binary_accuracy: 0.9766 - val_loss: 0.3668 - val_binary_accuracy: 0.9034\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 1s 396us/step - loss: 0.0463 - binary_accuracy: 0.9879 - val_loss: 0.3696 - val_binary_accuracy: 0.9034\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.0387 - binary_accuracy: 0.9886 - val_loss: 0.3786 - val_binary_accuracy: 0.9148\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 0s 322us/step - loss: 0.0449 - binary_accuracy: 0.9865 - val_loss: 0.3809 - val_binary_accuracy: 0.9148\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.0415 - binary_accuracy: 0.9879 - val_loss: 0.3936 - val_binary_accuracy: 0.9148\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 392us/step - loss: 0.0382 - binary_accuracy: 0.9865 - val_loss: 0.3953 - val_binary_accuracy: 0.9205\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 1s 367us/step - loss: 0.0310 - binary_accuracy: 0.9908 - val_loss: 0.3975 - val_binary_accuracy: 0.9205\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0333 - binary_accuracy: 0.9922 - val_loss: 0.4057 - val_binary_accuracy: 0.9148\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0420 - binary_accuracy: 0.9858 - val_loss: 0.4063 - val_binary_accuracy: 0.9148\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 1s 404us/step - loss: 0.0354 - binary_accuracy: 0.9901 - val_loss: 0.4033 - val_binary_accuracy: 0.9205\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1408 [==============================] - 1s 369us/step - loss: 0.0289 - binary_accuracy: 0.9901 - val_loss: 0.4024 - val_binary_accuracy: 0.9205\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.0392 - binary_accuracy: 0.9886 - val_loss: 0.3992 - val_binary_accuracy: 0.9205\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 370us/step - loss: 0.0428 - binary_accuracy: 0.9851 - val_loss: 0.3957 - val_binary_accuracy: 0.9205\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 389us/step - loss: 0.0344 - binary_accuracy: 0.9886 - val_loss: 0.3930 - val_binary_accuracy: 0.9205\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0272 - binary_accuracy: 0.9886 - val_loss: 0.3957 - val_binary_accuracy: 0.9205\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0276 - binary_accuracy: 0.9915 - val_loss: 0.4012 - val_binary_accuracy: 0.9205\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0284 - binary_accuracy: 0.9922 - val_loss: 0.4021 - val_binary_accuracy: 0.9205\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 1s 389us/step - loss: 0.0267 - binary_accuracy: 0.9915 - val_loss: 0.4026 - val_binary_accuracy: 0.9205\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 1s 387us/step - loss: 0.0269 - binary_accuracy: 0.9901 - val_loss: 0.4041 - val_binary_accuracy: 0.9205\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0299 - binary_accuracy: 0.9915 - val_loss: 0.4031 - val_binary_accuracy: 0.9205\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0322 - binary_accuracy: 0.9872 - val_loss: 0.4071 - val_binary_accuracy: 0.9205\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 1s 388us/step - loss: 0.0291 - binary_accuracy: 0.9915 - val_loss: 0.4065 - val_binary_accuracy: 0.9205\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 378us/step - loss: 0.0268 - binary_accuracy: 0.9915 - val_loss: 0.4084 - val_binary_accuracy: 0.9205\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 340us/step - loss: 0.0285 - binary_accuracy: 0.9908 - val_loss: 0.4080 - val_binary_accuracy: 0.9205\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0210 - binary_accuracy: 0.9936 - val_loss: 0.4081 - val_binary_accuracy: 0.9205\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 1s 365us/step - loss: 0.0261 - binary_accuracy: 0.9915 - val_loss: 0.4082 - val_binary_accuracy: 0.9205\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.0240 - binary_accuracy: 0.9936 - val_loss: 0.4093 - val_binary_accuracy: 0.9205\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0267 - binary_accuracy: 0.9901 - val_loss: 0.4088 - val_binary_accuracy: 0.9205\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.0262 - binary_accuracy: 0.9901 - val_loss: 0.4086 - val_binary_accuracy: 0.9205\n",
      "Epoch 45/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0202 - binary_accuracy: 0.9943 - val_loss: 0.4108 - val_binary_accuracy: 0.9205\n",
      "Epoch 46/100\n",
      "1408/1408 [==============================] - 1s 391us/step - loss: 0.0197 - binary_accuracy: 0.9922 - val_loss: 0.4116 - val_binary_accuracy: 0.9205\n",
      "Epoch 47/100\n",
      "1408/1408 [==============================] - 1s 400us/step - loss: 0.0276 - binary_accuracy: 0.9929 - val_loss: 0.4118 - val_binary_accuracy: 0.9205\n",
      "Epoch 48/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0247 - binary_accuracy: 0.9908 - val_loss: 0.4126 - val_binary_accuracy: 0.9205\n",
      "Epoch 49/100\n",
      "1408/1408 [==============================] - 0s 351us/step - loss: 0.0228 - binary_accuracy: 0.9936 - val_loss: 0.4123 - val_binary_accuracy: 0.9205\n",
      "Epoch 50/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.0261 - binary_accuracy: 0.9922 - val_loss: 0.4120 - val_binary_accuracy: 0.9205\n",
      "Epoch 51/100\n",
      "1408/1408 [==============================] - 1s 407us/step - loss: 0.0234 - binary_accuracy: 0.9957 - val_loss: 0.4118 - val_binary_accuracy: 0.9205\n",
      "1408/1408 [==============================] - 0s 139us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 125us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 132us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 939us/step - loss: 0.6611 - binary_accuracy: 0.6193 - val_loss: 0.6693 - val_binary_accuracy: 0.7557\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 1s 372us/step - loss: 0.4265 - binary_accuracy: 0.8139 - val_loss: 0.5935 - val_binary_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.2760 - binary_accuracy: 0.8821 - val_loss: 0.4966 - val_binary_accuracy: 0.8920\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.2217 - binary_accuracy: 0.9077 - val_loss: 0.4017 - val_binary_accuracy: 0.8864\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 1s 388us/step - loss: 0.1628 - binary_accuracy: 0.9361 - val_loss: 0.3356 - val_binary_accuracy: 0.8977\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 382us/step - loss: 0.1345 - binary_accuracy: 0.9524 - val_loss: 0.2942 - val_binary_accuracy: 0.8864\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.1168 - binary_accuracy: 0.9531 - val_loss: 0.2856 - val_binary_accuracy: 0.9034\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.1053 - binary_accuracy: 0.9609 - val_loss: 0.2604 - val_binary_accuracy: 0.9205\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0782 - binary_accuracy: 0.9723 - val_loss: 0.2688 - val_binary_accuracy: 0.9148\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 1s 378us/step - loss: 0.0779 - binary_accuracy: 0.9744 - val_loss: 0.2800 - val_binary_accuracy: 0.9148\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0721 - binary_accuracy: 0.9759 - val_loss: 0.3098 - val_binary_accuracy: 0.9205\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0546 - binary_accuracy: 0.9787 - val_loss: 0.3003 - val_binary_accuracy: 0.9261\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 0s 314us/step - loss: 0.0448 - binary_accuracy: 0.9872 - val_loss: 0.3034 - val_binary_accuracy: 0.9205\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0515 - binary_accuracy: 0.9830 - val_loss: 0.3301 - val_binary_accuracy: 0.9148\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0455 - binary_accuracy: 0.9822 - val_loss: 0.3110 - val_binary_accuracy: 0.9205\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 0s 339us/step - loss: 0.0346 - binary_accuracy: 0.9908 - val_loss: 0.3216 - val_binary_accuracy: 0.9205\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 0s 332us/step - loss: 0.0380 - binary_accuracy: 0.9929 - val_loss: 0.3186 - val_binary_accuracy: 0.9091\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0409 - binary_accuracy: 0.9872 - val_loss: 0.3233 - val_binary_accuracy: 0.9205\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0288 - binary_accuracy: 0.9908 - val_loss: 0.3179 - val_binary_accuracy: 0.9205\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 370us/step - loss: 0.0340 - binary_accuracy: 0.9886 - val_loss: 0.3401 - val_binary_accuracy: 0.9205\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0337 - binary_accuracy: 0.9886 - val_loss: 0.3486 - val_binary_accuracy: 0.9148\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 326us/step - loss: 0.0368 - binary_accuracy: 0.9865 - val_loss: 0.3361 - val_binary_accuracy: 0.9091\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 1s 367us/step - loss: 0.0310 - binary_accuracy: 0.9893 - val_loss: 0.3405 - val_binary_accuracy: 0.9205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 390us/step - loss: 0.0301 - binary_accuracy: 0.9901 - val_loss: 0.3429 - val_binary_accuracy: 0.9148\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0361 - binary_accuracy: 0.9872 - val_loss: 0.3458 - val_binary_accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0290 - binary_accuracy: 0.9879 - val_loss: 0.3682 - val_binary_accuracy: 0.9148\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 354us/step - loss: 0.0246 - binary_accuracy: 0.9901 - val_loss: 0.3567 - val_binary_accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 375us/step - loss: 0.0287 - binary_accuracy: 0.9886 - val_loss: 0.3630 - val_binary_accuracy: 0.9148\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 365us/step - loss: 0.0250 - binary_accuracy: 0.9957 - val_loss: 0.3619 - val_binary_accuracy: 0.9148\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 0s 335us/step - loss: 0.0288 - binary_accuracy: 0.9893 - val_loss: 0.3620 - val_binary_accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.0285 - binary_accuracy: 0.9901 - val_loss: 0.3667 - val_binary_accuracy: 0.9148\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0169 - binary_accuracy: 0.9957 - val_loss: 0.3650 - val_binary_accuracy: 0.9091\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0230 - binary_accuracy: 0.9936 - val_loss: 0.3667 - val_binary_accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 0s 330us/step - loss: 0.0213 - binary_accuracy: 0.9929 - val_loss: 0.3676 - val_binary_accuracy: 0.9148\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0252 - binary_accuracy: 0.9929 - val_loss: 0.3677 - val_binary_accuracy: 0.9148\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0241 - binary_accuracy: 0.9915 - val_loss: 0.3734 - val_binary_accuracy: 0.9205\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 1s 392us/step - loss: 0.0204 - binary_accuracy: 0.9922 - val_loss: 0.3701 - val_binary_accuracy: 0.9148\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0239 - binary_accuracy: 0.9922 - val_loss: 0.3682 - val_binary_accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 334us/step - loss: 0.0173 - binary_accuracy: 0.9972 - val_loss: 0.3682 - val_binary_accuracy: 0.9148\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 0s 342us/step - loss: 0.0255 - binary_accuracy: 0.9886 - val_loss: 0.3677 - val_binary_accuracy: 0.9148\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0211 - binary_accuracy: 0.9957 - val_loss: 0.3688 - val_binary_accuracy: 0.9148\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 1s 380us/step - loss: 0.0201 - binary_accuracy: 0.9922 - val_loss: 0.3673 - val_binary_accuracy: 0.9148\n",
      "1408/1408 [==============================] - 0s 132us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 136us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 133us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 935us/step - loss: 0.7001 - binary_accuracy: 0.5604 - val_loss: 0.6815 - val_binary_accuracy: 0.6023\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 1s 370us/step - loss: 0.5035 - binary_accuracy: 0.7521 - val_loss: 0.6286 - val_binary_accuracy: 0.7216\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.3434 - binary_accuracy: 0.8551 - val_loss: 0.5415 - val_binary_accuracy: 0.7898\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.2360 - binary_accuracy: 0.9034 - val_loss: 0.4473 - val_binary_accuracy: 0.8295\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.2071 - binary_accuracy: 0.9190 - val_loss: 0.3821 - val_binary_accuracy: 0.8352\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.1600 - binary_accuracy: 0.9453 - val_loss: 0.3492 - val_binary_accuracy: 0.8523\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.1203 - binary_accuracy: 0.9560 - val_loss: 0.3037 - val_binary_accuracy: 0.8636\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 360us/step - loss: 0.1090 - binary_accuracy: 0.9616 - val_loss: 0.2892 - val_binary_accuracy: 0.8693\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.1085 - binary_accuracy: 0.9581 - val_loss: 0.2794 - val_binary_accuracy: 0.8636\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0785 - binary_accuracy: 0.9730 - val_loss: 0.2748 - val_binary_accuracy: 0.8693\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 1s 387us/step - loss: 0.0663 - binary_accuracy: 0.9787 - val_loss: 0.2815 - val_binary_accuracy: 0.8580\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 1s 378us/step - loss: 0.0573 - binary_accuracy: 0.9808 - val_loss: 0.2932 - val_binary_accuracy: 0.8693\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 0s 355us/step - loss: 0.0449 - binary_accuracy: 0.9837 - val_loss: 0.3055 - val_binary_accuracy: 0.8693\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0425 - binary_accuracy: 0.9844 - val_loss: 0.3122 - val_binary_accuracy: 0.8693\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0443 - binary_accuracy: 0.9879 - val_loss: 0.3220 - val_binary_accuracy: 0.8693\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 407us/step - loss: 0.0426 - binary_accuracy: 0.9915 - val_loss: 0.3208 - val_binary_accuracy: 0.8636\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 0s 352us/step - loss: 0.0394 - binary_accuracy: 0.9865 - val_loss: 0.3183 - val_binary_accuracy: 0.8750\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 0s 334us/step - loss: 0.0365 - binary_accuracy: 0.9901 - val_loss: 0.3175 - val_binary_accuracy: 0.8693\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 1s 360us/step - loss: 0.0308 - binary_accuracy: 0.9929 - val_loss: 0.3199 - val_binary_accuracy: 0.8693\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 383us/step - loss: 0.0374 - binary_accuracy: 0.9879 - val_loss: 0.3263 - val_binary_accuracy: 0.8636\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 387us/step - loss: 0.0240 - binary_accuracy: 0.9957 - val_loss: 0.3258 - val_binary_accuracy: 0.8693\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0296 - binary_accuracy: 0.9915 - val_loss: 0.3246 - val_binary_accuracy: 0.8636\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0293 - binary_accuracy: 0.9915 - val_loss: 0.3248 - val_binary_accuracy: 0.8636\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 371us/step - loss: 0.0266 - binary_accuracy: 0.9943 - val_loss: 0.3261 - val_binary_accuracy: 0.8636\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 1s 370us/step - loss: 0.0278 - binary_accuracy: 0.9908 - val_loss: 0.3260 - val_binary_accuracy: 0.8636\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 0s 327us/step - loss: 0.0232 - binary_accuracy: 0.9950 - val_loss: 0.3265 - val_binary_accuracy: 0.8580\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.0240 - binary_accuracy: 0.9929 - val_loss: 0.3313 - val_binary_accuracy: 0.8693\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 1s 379us/step - loss: 0.0217 - binary_accuracy: 0.9950 - val_loss: 0.3345 - val_binary_accuracy: 0.8636\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 397us/step - loss: 0.0228 - binary_accuracy: 0.9929 - val_loss: 0.3352 - val_binary_accuracy: 0.8523\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0206 - binary_accuracy: 0.9943 - val_loss: 0.3376 - val_binary_accuracy: 0.8580\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 1s 360us/step - loss: 0.0193 - binary_accuracy: 0.9922 - val_loss: 0.3414 - val_binary_accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0226 - binary_accuracy: 0.9929 - val_loss: 0.3389 - val_binary_accuracy: 0.8636\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 1s 393us/step - loss: 0.0236 - binary_accuracy: 0.9943 - val_loss: 0.3413 - val_binary_accuracy: 0.8693\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0200 - binary_accuracy: 0.9950 - val_loss: 0.3409 - val_binary_accuracy: 0.8636\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0242 - binary_accuracy: 0.9908 - val_loss: 0.3439 - val_binary_accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 341us/step - loss: 0.0202 - binary_accuracy: 0.9915 - val_loss: 0.3433 - val_binary_accuracy: 0.8636\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 322us/step - loss: 0.0216 - binary_accuracy: 0.9950 - val_loss: 0.3439 - val_binary_accuracy: 0.8636\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 0s 331us/step - loss: 0.0228 - binary_accuracy: 0.9929 - val_loss: 0.3447 - val_binary_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 324us/step - loss: 0.0145 - binary_accuracy: 0.9964 - val_loss: 0.3443 - val_binary_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 0s 346us/step - loss: 0.0216 - binary_accuracy: 0.9915 - val_loss: 0.3444 - val_binary_accuracy: 0.8636\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0220 - binary_accuracy: 0.9915 - val_loss: 0.3452 - val_binary_accuracy: 0.8636\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.0203 - binary_accuracy: 0.9957 - val_loss: 0.3449 - val_binary_accuracy: 0.8636\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.0199 - binary_accuracy: 0.9964 - val_loss: 0.3449 - val_binary_accuracy: 0.8636\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0242 - binary_accuracy: 0.9950 - val_loss: 0.3449 - val_binary_accuracy: 0.8636\n",
      "Epoch 45/100\n",
      "1408/1408 [==============================] - 1s 375us/step - loss: 0.0182 - binary_accuracy: 0.9950 - val_loss: 0.3450 - val_binary_accuracy: 0.8636\n",
      "Epoch 46/100\n",
      "1408/1408 [==============================] - 1s 385us/step - loss: 0.0179 - binary_accuracy: 0.9964 - val_loss: 0.3450 - val_binary_accuracy: 0.8636\n",
      "Epoch 47/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0163 - binary_accuracy: 0.9950 - val_loss: 0.3451 - val_binary_accuracy: 0.8693\n",
      "1408/1408 [==============================] - 0s 128us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 134us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 136us/step\n",
      "(176,)\n",
      "(176,)\n",
      "(176, 41, 4) (1408, 41, 4)\n",
      "(1408, 41, 4) (176, 41, 4) (176, 41, 4)\n",
      "Train on 1408 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "1408/1408 [==============================] - 1s 902us/step - loss: 0.7416 - binary_accuracy: 0.5291 - val_loss: 0.6892 - val_binary_accuracy: 0.5795\n",
      "Epoch 2/100\n",
      "1408/1408 [==============================] - 1s 375us/step - loss: 0.6130 - binary_accuracy: 0.6619 - val_loss: 0.6565 - val_binary_accuracy: 0.6989\n",
      "Epoch 3/100\n",
      "1408/1408 [==============================] - 1s 359us/step - loss: 0.4385 - binary_accuracy: 0.8033 - val_loss: 0.5374 - val_binary_accuracy: 0.7898\n",
      "Epoch 4/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.3360 - binary_accuracy: 0.8530 - val_loss: 0.4130 - val_binary_accuracy: 0.8864\n",
      "Epoch 5/100\n",
      "1408/1408 [==============================] - 0s 336us/step - loss: 0.2622 - binary_accuracy: 0.8928 - val_loss: 0.3061 - val_binary_accuracy: 0.9432\n",
      "Epoch 6/100\n",
      "1408/1408 [==============================] - 1s 395us/step - loss: 0.2290 - binary_accuracy: 0.9148 - val_loss: 0.2119 - val_binary_accuracy: 0.9545\n",
      "Epoch 7/100\n",
      "1408/1408 [==============================] - 0s 350us/step - loss: 0.1799 - binary_accuracy: 0.9325 - val_loss: 0.1557 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.1766 - binary_accuracy: 0.9368 - val_loss: 0.1079 - val_binary_accuracy: 0.9659\n",
      "Epoch 9/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.1381 - binary_accuracy: 0.9482 - val_loss: 0.0861 - val_binary_accuracy: 0.9830\n",
      "Epoch 10/100\n",
      "1408/1408 [==============================] - 1s 375us/step - loss: 0.1256 - binary_accuracy: 0.9474 - val_loss: 0.0577 - val_binary_accuracy: 0.9830\n",
      "Epoch 11/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.1137 - binary_accuracy: 0.9567 - val_loss: 0.0566 - val_binary_accuracy: 0.9886\n",
      "Epoch 12/100\n",
      "1408/1408 [==============================] - 1s 358us/step - loss: 0.1008 - binary_accuracy: 0.9638 - val_loss: 0.0451 - val_binary_accuracy: 0.9886\n",
      "Epoch 13/100\n",
      "1408/1408 [==============================] - 1s 398us/step - loss: 0.0880 - binary_accuracy: 0.9688 - val_loss: 0.0490 - val_binary_accuracy: 0.9716\n",
      "Epoch 14/100\n",
      "1408/1408 [==============================] - 1s 368us/step - loss: 0.0945 - binary_accuracy: 0.9666 - val_loss: 0.0379 - val_binary_accuracy: 0.9943\n",
      "Epoch 15/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0749 - binary_accuracy: 0.9751 - val_loss: 0.0347 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.0695 - binary_accuracy: 0.9780 - val_loss: 0.0317 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0696 - binary_accuracy: 0.9716 - val_loss: 0.0287 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1408/1408 [==============================] - 1s 363us/step - loss: 0.0639 - binary_accuracy: 0.9773 - val_loss: 0.0251 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0616 - binary_accuracy: 0.9794 - val_loss: 0.0214 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.0463 - binary_accuracy: 0.9872 - val_loss: 0.0207 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1408/1408 [==============================] - 1s 385us/step - loss: 0.0525 - binary_accuracy: 0.9822 - val_loss: 0.0187 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1408/1408 [==============================] - 1s 364us/step - loss: 0.0497 - binary_accuracy: 0.9844 - val_loss: 0.0193 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1408/1408 [==============================] - 1s 357us/step - loss: 0.0397 - binary_accuracy: 0.9872 - val_loss: 0.0190 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1408/1408 [==============================] - 1s 355us/step - loss: 0.0598 - binary_accuracy: 0.9766 - val_loss: 0.0182 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1408/1408 [==============================] - 1s 376us/step - loss: 0.0447 - binary_accuracy: 0.9858 - val_loss: 0.0170 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1408/1408 [==============================] - 1s 384us/step - loss: 0.0581 - binary_accuracy: 0.9808 - val_loss: 0.0178 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0420 - binary_accuracy: 0.9851 - val_loss: 0.0164 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1408/1408 [==============================] - 0s 353us/step - loss: 0.0339 - binary_accuracy: 0.9908 - val_loss: 0.0171 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1408/1408 [==============================] - 1s 366us/step - loss: 0.0348 - binary_accuracy: 0.9879 - val_loss: 0.0168 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1408/1408 [==============================] - 1s 393us/step - loss: 0.0363 - binary_accuracy: 0.9901 - val_loss: 0.0171 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1408/1408 [==============================] - 1s 362us/step - loss: 0.0375 - binary_accuracy: 0.9879 - val_loss: 0.0178 - val_binary_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "1408/1408 [==============================] - 0s 347us/step - loss: 0.0359 - binary_accuracy: 0.9865 - val_loss: 0.0192 - val_binary_accuracy: 0.9886\n",
      "Epoch 33/100\n",
      "1408/1408 [==============================] - 1s 361us/step - loss: 0.0368 - binary_accuracy: 0.9879 - val_loss: 0.0173 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1408/1408 [==============================] - 1s 386us/step - loss: 0.0432 - binary_accuracy: 0.9865 - val_loss: 0.0171 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0343 - binary_accuracy: 0.9872 - val_loss: 0.0163 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1408/1408 [==============================] - 0s 344us/step - loss: 0.0373 - binary_accuracy: 0.9872 - val_loss: 0.0166 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1408/1408 [==============================] - 0s 338us/step - loss: 0.0273 - binary_accuracy: 0.9950 - val_loss: 0.0166 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1408/1408 [==============================] - 1s 377us/step - loss: 0.0409 - binary_accuracy: 0.9858 - val_loss: 0.0172 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1408/1408 [==============================] - 0s 349us/step - loss: 0.0354 - binary_accuracy: 0.9858 - val_loss: 0.0176 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1408/1408 [==============================] - 0s 345us/step - loss: 0.0297 - binary_accuracy: 0.9886 - val_loss: 0.0173 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1408/1408 [==============================] - 0s 343us/step - loss: 0.0412 - binary_accuracy: 0.9858 - val_loss: 0.0163 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1408/1408 [==============================] - 1s 356us/step - loss: 0.0342 - binary_accuracy: 0.9879 - val_loss: 0.0162 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1408/1408 [==============================] - 1s 381us/step - loss: 0.0345 - binary_accuracy: 0.9886 - val_loss: 0.0166 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1408/1408 [==============================] - 0s 340us/step - loss: 0.0297 - binary_accuracy: 0.9915 - val_loss: 0.0173 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1408/1408 [==============================] - 0s 348us/step - loss: 0.0335 - binary_accuracy: 0.9879 - val_loss: 0.0173 - val_binary_accuracy: 1.0000\n",
      "1408/1408 [==============================] - 0s 134us/step\n",
      "(1408,)\n",
      "(1408,)\n",
      "176/176 [==============================] - 0s 129us/step\n",
      "(176,)\n",
      "(176,)\n",
      "176/176 [==============================] - 0s 135us/step\n",
      "(176,)\n",
      "(176,)\n",
      "                                     training_results\n",
      "0   sn : mean : 0.9907670454545453 std : 0.0115091...\n",
      "1   sp : mean : 0.9973011363636364 std : 0.0025764...\n",
      "2   acc : mean : 0.994034081697464 std : 0.0059945...\n",
      "3   MCC : mean : 0.9881539388802052 std : 0.011843...\n",
      "4   AUC : mean : 0.9996103838455579 std : 0.000512...\n",
      "5   precision : mean : 0.9972872056783931 std : 0....\n",
      "6   F1 : mean : 0.9939824173535371 std : 0.0060904...\n",
      "7     lossValue : mean : 0.029732859 std : 0.01957309\n",
      "8                      ______________________________\n",
      "9                                  validation_results\n",
      "10  sn : mean : 0.946590909090909 std : 0.03804697...\n",
      "11  sp : mean : 0.9579545454545455 std : 0.0380469...\n",
      "12  acc : mean : 0.9522727251052856 std : 0.037188...\n",
      "13  MCC : mean : 0.9047195161534537 std : 0.074365...\n",
      "14  AUC : mean : 0.9806689049586778 std : 0.017417...\n",
      "15  precision : mean : 0.9575921454644998 std : 0....\n",
      "16  F1 : mean : 0.9519965167263565 std : 0.0372590...\n",
      "17     lossValue : mean : 0.18517038 std : 0.11496075\n",
      "18                     ______________________________\n",
      "19                                    testing_results\n",
      "20  sn : mean : 0.9374999999999998 std : 0.0425946...\n",
      "21  sp : mean : 0.9499999999999998 std : 0.0341665...\n",
      "22     acc : mean : 0.94375 std : 0.03642130084144319\n",
      "23  MCC : mean : 0.8878476708651611 std : 0.072714...\n",
      "24  AUC : mean : 0.9798682851239668 std : 0.016102...\n",
      "25  precision : mean : 0.94933833817182 std : 0.03...\n",
      "26  F1 : mean : 0.9432213392615644 std : 0.0370953...\n",
      "27     lossValue : mean : 0.19327396 std : 0.10450195\n",
      "28                     ______________________________\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 31 10:17:08 2020\n",
    "\n",
    "@author: zeeshan\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 19 11:03:59 2020\n",
    "\n",
    "@author: zeeshan\n",
    "\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 11 16:27:11 2020\n",
    "\n",
    "@author: Zeeshan\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\";\n",
    "\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input,MaxPooling1D,Flatten,LeakyReLU,Activation,concatenate,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from group_norm import GroupNormalization\n",
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.metrics import binary_accuracy\n",
    "from sklearn.metrics import confusion_matrix,recall_score,matthews_corrcoef,roc_curve,roc_auc_score,auc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "import os, sys, copy, getopt, re, argparse\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "np.random.seed(seed=21)\n",
    "tf.__version__\n",
    "keras.__version__\n",
    "\n",
    "from keras import losses\n",
    "import pickle\n",
    "from scipy import interp\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "def analyze(temp, OutputDir):\n",
    "\n",
    "    # temp = None\n",
    "    # with open(dataFile, 'rb') as file:\n",
    "    #        temp = pickle.load(file)\n",
    "\n",
    "    trainning_result, validation_result, testing_result = temp;\n",
    "\n",
    "    file = open(OutputDir + '/performance.txt', 'w')\n",
    "\n",
    "    index = 0\n",
    "    for x in [trainning_result, validation_result, testing_result]:\n",
    "\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'training_'\n",
    "        if index == 1:\n",
    "            title = 'validation_'\n",
    "        if index == 2:\n",
    "            title = 'testing_'\n",
    "\n",
    "        index += 1;\n",
    "\n",
    "        file.write(title +  'results\\n')\n",
    "\n",
    "\n",
    "        for j in ['sn', 'sp', 'acc', 'MCC', 'AUC', 'precision', 'F1', 'lossValue']:\n",
    "\n",
    "            total = []\n",
    "\n",
    "            for val in x:\n",
    "                total.append(val[j])\n",
    "\n",
    "            file.write(j + ' : mean : ' + str(np.mean(total)) + ' std : ' + str(np.std(total))  + '\\n')\n",
    "\n",
    "        file.write('\\n\\n______________________________\\n')\n",
    "    file.close();\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for x in [trainning_result, validation_result, testing_result]:\n",
    "\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for val in x:\n",
    "            tpr = val['tpr']\n",
    "            fpr = val['fpr']\n",
    "            tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC fold %d (AUC = %0.2f)' % (i+1, roc_auc))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        print;\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'training_'\n",
    "        if index == 1:\n",
    "            title = 'validation_'\n",
    "        if index == 2:\n",
    "            title = 'testing_'\n",
    "\n",
    "        plt.savefig( OutputDir + '/' + title +'ROC.png')\n",
    "        plt.close('all');\n",
    "\n",
    "        index += 1;\n",
    "\n",
    "##############################   Scheduler ########################\n",
    "def scheduler(epochs, lr):\n",
    "  if epochs < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "####################################################################\n",
    "    \n",
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "    \n",
    "    return out\n",
    "\n",
    "def calculate(sequence):\n",
    "\n",
    "    X = []\n",
    "    dictNum = {'A' : 0, 'T' : 0, 'C' : 0, 'G' : 0};\n",
    "\n",
    "    for i in range(len(sequence)):\n",
    "\n",
    "        if sequence[i] in dictNum.keys():\n",
    "            dictNum[sequence[i]] += 1;\n",
    "            X.append(dictNum[sequence[i]] / float(i + 1));\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "def dataProcessing(path):\n",
    "\n",
    "    data = pd.read_csv(path);\n",
    "    alphabet = np.array(['A', 'G', 'T', 'C','0'])\n",
    "    X = [];\n",
    "    for line in data['data']:\n",
    "\n",
    "        line = list(line.strip('\\n'));\n",
    "        #scoreSequence = calculate2(line);\n",
    "        \n",
    "        seq = np.array(line, dtype = '|U1').reshape(-1,1);\n",
    "        seq_data = []\n",
    "\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == 'A':\n",
    "                seq_data.append([1,0,0,0])\n",
    "            if seq[i] == 'T':\n",
    "                seq_data.append([0,1,0,0])\n",
    "            if seq[i] == 'C':\n",
    "                seq_data.append([0,0,1,0])\n",
    "            if seq[i] == 'G':\n",
    "                seq_data.append([0,0,0,1])\n",
    "            if seq[i] == '0':\n",
    "                seq_data.append([0,0,0,0])\n",
    "                \n",
    "        X.append(np.array(seq_data));\n",
    "        \n",
    "    X = np.array(X);\n",
    "    y = np.array(data['label'], dtype = np.int32);\n",
    " \n",
    "    return X, y; #(n, 34, 4), (n,)\n",
    "\n",
    "def prepareData(PositiveCSV, NegativeCSV):\n",
    "\n",
    "    Positive_X, Positive_y = dataProcessing(PositiveCSV);\n",
    "    Negitive_X, Negitive_y = dataProcessing(NegativeCSV);\n",
    "\n",
    "    return Positive_X, Positive_y, Negitive_X, Negitive_y\n",
    "\n",
    "def shuffleData(X, y):\n",
    "    index = [i for i in range(len(X))]\n",
    "    random.shuffle(index)\n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    return X, y;\n",
    "\n",
    "#*******************Arch 3***********************#\n",
    "#************************************************#\n",
    "def spinal_cnn():\n",
    "    input_shape = (41,4)\n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    \n",
    "    conv0 = Conv1D(filters=16, kernel_size=5,strides=1)(inputs)\n",
    "    normLayer0 = BatchNormalization()(conv0);\n",
    "    #pool0 = MaxPooling1D(pool_size = 2)(normLayer0)\n",
    "    act0 = Activation(activation='relu')(normLayer0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # conv1 = Conv1D(filters=16, kernel_size=5,strides=1)(act0)\n",
    "    # normLayer1 = BatchNormalization()(conv1);\n",
    "    # pool1 = MaxPooling1D(pool_size = 2)(normLayer1)\n",
    "    # act1 = Activation(activation='relu')(pool1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=32, kernel_size=5,strides=1)(act0)\n",
    "    normLayer2 = BatchNormalization()(conv2);\n",
    "    pool2 = MaxPooling1D(pool_size = 2)(normLayer2)\n",
    "    dropoutLayer1 = Dropout(0.35)(pool2)\n",
    "    act2 = Activation(activation='relu')(dropoutLayer1)\n",
    "    \n",
    "    x = Flatten()(act2)\n",
    "    \n",
    "    #x1 = keras.layers.Lambda(lambda x: x[:,0:112], output_shape=(112,))(x)\n",
    "    #x2 = keras.layers.Lambda(lambda x: x[:,112:], output_shape=(112,))(x)\n",
    "    \n",
    "    \n",
    "    #**************************************\n",
    "    \n",
    "    # conv3 = Conv1D(filters=64, kernel_size=5,strides=1)(act0)\n",
    "    # normLayer3 = BatchNormalization()(conv3);\n",
    "    # pool3 = MaxPooling1D(pool_size = 2)(normLayer3)\n",
    "    # act3 = Activation(activation='relu')(pool3)\n",
    "    \n",
    "    conv4 = Conv1D(filters=128, kernel_size=5,strides=1)(act0)\n",
    "    normLayer4 = BatchNormalization()(conv4);\n",
    "    pool4 = MaxPooling1D(pool_size = 2)(normLayer4)\n",
    "    dropoutLayer2 = Dropout(0.35)(pool4)\n",
    "    act4 = Activation(activation='relu')(dropoutLayer2)\n",
    "    \n",
    "    #conv3 = Conv1D(filters=64, kernel_size=5, strides=1)(pool2)\n",
    "    #pool3 = MaxPooling1D(pool_size = 2)(conv3)\n",
    "    #dropoutLayer = Dropout(0.25)(pool3) # Drop outtttttttt ############\n",
    "    #pool3 = Activation(activation='relu')(dropoutLayer)\n",
    "    \n",
    "    \n",
    "    a = Flatten()(act4)\n",
    "    comb = concatenate([x, a], axis=1)\n",
    "    \n",
    "    a1 = keras.layers.Lambda(lambda comb: comb[:,0:1280], output_shape=(1280,))(comb)\n",
    "    a2 = keras.layers.Lambda(lambda comb: comb[:,1280:], output_shape=(1280,))(comb)\n",
    "    \n",
    "    #x1 = x[:, 0:360]\n",
    "    \n",
    "    a1 = Dense(8, activation='relu')(a1) # Number of nodes in hidden layer\n",
    "    \n",
    "    a2 = concatenate([a2, a1])\n",
    "    a2 = Dense(8, activation='relu')(a2)\n",
    "    \n",
    "    a3 = concatenate([a1, a2])\n",
    "    a3 = Dense(8, activation='relu')(a3)\n",
    "    \n",
    "    a4 = concatenate([a2, a3])\n",
    "    a4 = Dense(8, activation='relu')(a4)\n",
    "    \n",
    "    a5 = concatenate([a1, a4])\n",
    "    a5 = Dense(8, activation='relu')(a3)\n",
    "    \n",
    "    a6 = concatenate([a2, a5])\n",
    "    a6 = Dense(8, activation='relu')(a6)\n",
    "    \n",
    "    a = concatenate([a1, a2], axis=1)\n",
    "    a = concatenate([a, a3], axis=1)\n",
    "    a = concatenate([a, a4], axis=1)\n",
    "    a = concatenate([a, a5], axis=1)\n",
    "    a = concatenate([a, a6], axis=1)\n",
    "    \n",
    "    #xa = concatenate([a, x], axis=1)\n",
    "    \n",
    "    \n",
    "    output = Dense(1, activation= 'sigmoid')(a)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    opt=SGD(learning_rate=0.001, momentum = 0.95)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= opt, metrics=[binary_accuracy]);\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def calculateScore(X, y, model, folds):\n",
    "    \n",
    "    score = model.evaluate(X,y)\n",
    "    pred_y = model.predict(X)\n",
    "\n",
    "    accuracy = score[1];\n",
    "\n",
    "    tempLabel = np.zeros(shape = y.shape, dtype=np.int32)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if pred_y[i] < 0.5:\n",
    "            tempLabel[i] = 0;\n",
    "        else:\n",
    "            tempLabel[i] = 1;\n",
    "    confusion = confusion_matrix(y, tempLabel)\n",
    "    TN, FP, FN, TP = confusion.ravel()\n",
    "\n",
    "    sensitivity = recall_score(y, tempLabel)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    MCC = matthews_corrcoef(y, tempLabel)\n",
    "\n",
    "    F1Score = (2 * TP) / float(2 * TP + FP + FN)\n",
    "    precision = TP / float(TP + FP)\n",
    "\n",
    "    pred_y = pred_y.reshape((-1, ))\n",
    "\n",
    "    ROCArea = roc_auc_score(y, pred_y)\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred_y)\n",
    "    lossValue = None;\n",
    "\n",
    "    print(y.shape)\n",
    "    print(pred_y.shape)\n",
    "\n",
    "    y_true = tf.convert_to_tensor(y, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(pred_y, np.float32)\n",
    "    \n",
    "    plt.show() #Extraaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
    "    #np.save('/home/zeeshan/SNNRice6mA-master/Output_test/chunk_folds/'+str(test_index)+'_'+'x_test',test_X)\n",
    "    #def figs(folds):\n",
    "    \n",
    "    #for fig in range(0, folds):\n",
    "      #plt.savefig('/home/zeeshan/SNNRice6mA-master/Output_test/fold_'+str(fig)+'.png')\n",
    "      \n",
    "        \n",
    "    #figs(folds)  # Extraaaaaaaaaaaaaaaa\n",
    "    #plt.savefig( OutputDir + '/' + title +'ROC.png')\n",
    "    \n",
    "    #with tf.compat.v1.Session():\n",
    "    #with tf.Session():\n",
    "    lossValue = losses.binary_crossentropy(y_true, y_pred)#.eval()\n",
    "\n",
    "    return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea, 'precision' : precision, 'F1' : F1Score, 'fpr' : fpr, 'tpr' : tpr, 'thresholds' : thresholds, 'lossValue' : lossValue}\n",
    "\n",
    "def funciton(PositiveCSV, NegativeCSV, OutputDir, folds):\n",
    "\n",
    "    Positive_X, Positive_y, Negitive_X, Negitive_y = prepareData(PositiveCSV, NegativeCSV)\n",
    "    \n",
    "    random.shuffle(Positive_X);\n",
    "    random.shuffle(Negitive_X);\n",
    "\n",
    "    Positive_X_Slices = chunkIt(Positive_X, folds);\n",
    "    Positive_y_Slices = chunkIt(Positive_y, folds);\n",
    "\n",
    "    Negative_X_Slices = chunkIt(Negitive_X, folds);\n",
    "    Negative_y_Slices = chunkIt(Negitive_y, folds);\n",
    "\n",
    "    trainning_result = []\n",
    "    validation_result = []\n",
    "    testing_result = []\n",
    "    \n",
    "    for test_index in range(folds):\n",
    "\n",
    "        test_X = np.concatenate((Positive_X_Slices[test_index],Negative_X_Slices[test_index]))\n",
    "        test_y = np.concatenate((Positive_y_Slices[test_index],Negative_y_Slices[test_index]))\n",
    "\n",
    "        validation_index = (test_index+1) % folds;\n",
    "\n",
    "        valid_X = np.concatenate((Positive_X_Slices[validation_index],Negative_X_Slices[validation_index]))\n",
    "        valid_y = np.concatenate((Positive_y_Slices[validation_index],Negative_y_Slices[validation_index]))\n",
    "\n",
    "        start = 0;\n",
    "\n",
    "        for val in range(0, folds):\n",
    "            if val != test_index and val != validation_index:\n",
    "                start = val;\n",
    "                break;\n",
    "\n",
    "        train_X = np.concatenate((Positive_X_Slices[start],Negative_X_Slices[start]))\n",
    "        train_y = np.concatenate((Positive_y_Slices[start],Negative_y_Slices[start]))\n",
    "\n",
    "        for i in range(0, folds):\n",
    "            if i != test_index and i != validation_index and i != start:\n",
    "                tempX = np.concatenate((Positive_X_Slices[i],Negative_X_Slices[i]))\n",
    "                tempy = np.concatenate((Positive_y_Slices[i],Negative_y_Slices[i]))\n",
    "\n",
    "                \n",
    "                train_X = np.concatenate((train_X, tempX))\n",
    "                train_y = np.concatenate((train_y, tempy))\n",
    "        print(np.shape(tempX),np.shape(train_X))\n",
    "        test_X, test_y = shuffleData(test_X,test_y);\n",
    "        valid_X,valid_y = shuffleData(valid_X,valid_y)\n",
    "        train_X,train_y = shuffleData(train_X,train_y);\n",
    "        \n",
    "        print(np.shape(train_X), np.shape(valid_X), np.shape(test_X))\n",
    "        \n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'x_test',test_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'y_test',test_y)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'valid_X',valid_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'valid_y',valid_y)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'x_train',train_X)\n",
    "        np.save('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen/chunk_folds/'+str(test_index)+'_'+'y_train',train_y)\n",
    "        \n",
    "        \n",
    "        model = spinal_cnn();\n",
    "        #model = getMode();\n",
    "        \n",
    "        result_folder = OutputDir\n",
    "        if not os.path.exists(result_folder):\n",
    "            os.makedirs(result_folder)\n",
    "        model_results_folder=result_folder\n",
    "        \n",
    "        #best_weights = model_results_folder + 'best_weights.h5'\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_binary_accuracy', patience= 30, restore_best_weights=True)\n",
    "        model_check = ModelCheckpoint(filepath = OutputDir + \"/model\" + str(test_index+1) +\".h5\", monitor = 'val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "        #reduct_L_rate = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=20)\n",
    "        reduct_L_rate = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        \n",
    "        cbacks = [model_check, early_stopping,reduct_L_rate]\n",
    "        #cbacks = [model_check, early_stopping]\n",
    "        \n",
    "        #####################Call back #########################\n",
    "        #callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        ########################################################\n",
    "        \n",
    "        history = model.fit(train_X, train_y, batch_size = 32, epochs = 100, validation_data = (valid_X, valid_y),callbacks = cbacks);\n",
    "        \n",
    "        \n",
    "        trainning_result.append(calculateScore(train_X, train_y, model, folds));\n",
    "        validation_result.append(calculateScore(valid_X, valid_y, model, folds));\n",
    "        testing_result.append(calculateScore(test_X, test_y, model, folds));\n",
    "\n",
    "    temp_dict = (trainning_result, validation_result, testing_result)\n",
    "    analyze(temp_dict, OutputDir);\n",
    "    \n",
    "\n",
    "\n",
    "PositiveCSV = 'Chen_Positive_lab.txt'\n",
    "NegativeCSV = 'Chen_Negative_lab.txt'\n",
    "#PositiveCSV = 'Positive_Chen.txt'\n",
    "#NegativeCSV = 'Negative_Chen.txt'\n",
    "#OutputDir = 'D:/Zeeshan/Methylation/SNNRice6ma/SNNRice6mA-Zeeshan'\n",
    "OutputDir = '/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen_again/'\n",
    "funciton(PositiveCSV, NegativeCSV, OutputDir, 10);\n",
    "\n",
    "result = pd.read_csv('/home/zeeshan/SNNRice6mA-master/Output_Arch4_a_chen_again/performance.txt')\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
